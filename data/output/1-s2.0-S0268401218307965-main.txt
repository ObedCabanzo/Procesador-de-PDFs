# International Journal of Information Management 50 (2020) 261–272
# Contents lists available at ScienceDirect
# Information Management
# International Journal of Information Management
# ELSEVIER
# journal homepage: www.elsevier.com/locate/ijinfomgt
# Mobile users’ information privacy concerns and the role of app permission requests
# Kenan Degirmenci
School of Information Systems, Queensland University of Technology, 2 George Street, Brisbane QLD 4000, Australia
# A R T I C L E I N F O
# A B S T R A C T
# Keywords:
Mobile users, App permission requests, Information privacy concerns, Online survey, Structural equation modeling
Recent privacy-related incidents of mobile services have shown that app stores and providers face the challenge of mobile users’ information privacy concerns, which can prevent users from installing mobile apps or induce them to uninstall an app. In this paper, we investigate the role of app permission requests and compare the impact on privacy concerns with other antecedents of information privacy concerns, i.e., prior privacy experience, computer anxiety, and perceived control. To test these effects empirically, we conducted an online survey with 775 participants. Results of our structural equation modeling show that prior privacy experience, computer anxiety, and perceived control have significant effects on privacy concerns. However, concerns for app permission requests have approximately twice as much predictive value than the other factors put together to explain mobile users’ overall information privacy concerns. We expect that our findings can provide a theoretical contribution for future mobile privacy research as well as practical implications for app stores and providers.
# 1. Introduction
Once again, information privacy concerns have been in the main focus of the most recent Facebook privacy scandal, where 14 million users have unknowingly posted private information to the public due to a software bug . Earlier this year, Facebook was under investigation due to the use of its data by political consulting firm Cambridge Analytica, which collected personal information of approximately 87 million Facebook users without their explicit consent to access their data . Social networking services other than Facebook have also been at the heart of information privacy concerns. For example, a few years ago, the social networking app Path had collected personal information from mobile users’ address books without their knowledge and consent . Such privacy-related incidents that mobile users may experience are one of a few reasons for them to abandon the use of mobile apps. In a survey of 714 mobile app users, the Pew Research Center found that 54 percent of the respondents had decided not to install and 30 percent had decided to uninstall mobile apps due to privacy concerns about their personal information (Boyles, Smith, & Madden, 2012). Although the access to personal information can be advantageous for mobile users, for example, the access to location is used for navigation purposes by some apps, it also evokes privacy concerns with the result that users delete apps from their devices (eMarketer, 2016). For app providers, it is therefore important to understand and alleviate mobile users’ concerns for their information privacy.
E-mail address: kenan.degirmenci@qut.edu.au.
https://doi.org/10/j.ijinfomgt
Received 9 August 2018; Received in revised form 5 April 2019; Accepted 14 May 2019; Available online 02 July 2019
0268-4012/ © 2019 Elsevier Ltd. All rights reserved.
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
privacy concerns. To that end, we expect that our results will provide implications, which will be relevant to app stores and providers regarding decision-making of implementing app permissions, such that privacy concerns can be further mitigated. As an initial step, our survey-based data analysis reveals a problem with existing designs of permission requests, which refers to app permission concerns and offers implications for practice and directions for future research. Based on the findings of our study, we anticipate that the design of app permission requests will require a change due to mobile users’ growing privacy concerns, which we discuss more in-depth in Sections 6 and 7.
The purpose of this paper is to investigate the role of app permission requests regarding mobile users’ concerns for information privacy. To address this gap, we draw on the construct of mobile users’ information privacy concerns (MUIPC) (Xu, Gupta, Rosson, & Carroll, 2012) to measure users’ privacy concerns in a mobile context, and we situate our research within the framework of the overarching macro model labeled “Antecedents–Privacy Concerns–Outcomes” (APCO) (Dinev, McConnell, & Smith, 2015; Smith, Dinev, & Xu, 2011), of which we focus on the antecedents of prior privacy experience (Smith, Milberg, & Burke, 1996), computer anxiety (Stewart & Segars, 2002), and perceived control . In our mobile user context, we add app permission concerns as an antecedent of MUIPC and propose the following research question: What impact do app permission concerns have on mobile users’ overall information privacy concerns compared to the privacy-related antecedents prior privacy experience, computer anxiety, and perceived control? The paper is structured as follows: First, a theoretical foundation of the MUIPC construct and antecedents of information privacy concerns is presented, followed by our research model and hypothesis generation. Then, we describe the research design and show results from our survey-based data analysis. Following the discussion of our findings, we provide a contribution to theory and implications for practice. Finally, we conclude with limitations and future research directions.
# 2. Theoretical foundation
# 2. Mobile users’ information privacy concerns
The MUIPC construct was first introduced by Xu, Gupta et al. (2012), which is based on the scale of concern for information privacy (CFIP)  and Internet users’ information privacy concerns (IUIPC) (Malhotra, Kim, & Agarwal, 2004). The CFIP scale measures “individuals’ concerns about organizational information privacy practices” with four subscales: collection, errors, improper access, and unauthorized secondary use (Smith et al., 1996, p. 169). Collection describes individuals’ perception that “great quantities of data regarding their personalities, background, and actions are being accumulated” (Smith et al., 1996, p. 171). The collection of personal information enables companies to use this information about individuals in relationship marketing and to target offers more accurately to individuals’ interests (Culnan & Armstrong, 1999). Due to errors and improper access, individuals become concerned that companies should take more measures to reduce errors and control access to personal information . With regard to companies’ potential opportunistic behaviors (Laufer & Wolfe, 1977), unauthorized secondary use refers to the selling or sharing of a person’s information without their authorization . Referring to Malhotra et al. (2004), IUIPC serves as a “tool for analyzing online consumers’ privacy concerns and reactions to various privacy threats on the Internet” (p. 348), which draws on the social contract and justice theories, identifying three dimensions of privacy concerns: collection of personal information (distributive justice), control over personal information (procedural justice), and awareness of organizational information privacy practices (interactional and informational justice).
Building on these privacy-related constructs, MUIPC draws on the communication privacy management theory and relates to information privacy concerns in a mobile user context, which is divided into three dimensions to measure mobile users’ concerns: perceived surveillance, perceived intrusion, and secondary use of personal information. Perceived surveillance describes the tracking and profiling of mobile users through mobile technology capabilities , which are equipped with environment sensors such as built-in cameras, proximity sensors, accelerometers, gyroscopes, and global positioning system (GPS) receivers (Enck, 2011; Lienhard & Legner, 2015). In a taxonomy of privacy, Solove (2006, p. 490) defines surveillance as “the watching, listening to, or recording of an individual’s activities”. The sensors in mobile devices allow diverse possibilities regarding users’ environment, movement, orientation, and location, and thus, they enable to enhance mobile users’ tasks; however, at the same time, the sensors may evoke privacy risks and can lead to information disclosure (Keith, Babb, Lowry, Furner, & Abdullat, 2015; Zhang, Adipat, & Mowafi, 2009), which is closely related to an intrusion of mobile users’ privacy. Solove (2006, p. 549) defines intrusion as “invasions or incursions into one’s life. It disturbs the victim’s daily activities, alters her routines, destroys her solitude, and often makes her feel uncomfortable and uneasy”. For example, Google Maps or Apple Maps request access to the location of mobile users and as a result, users’ location is exposed. While this function is fundamental for the functionality of the navigation system of these apps, access is requested unnecessarily in a number of cases by other apps , leading to privacy intrusion and malicious use of personal information such as secondary use. Secondary use of personal information, which is also a dimension of CFIP, is defined as “the use of data for purposes unrelated to the purposes for which the data was initially collected without the data subject’s consent” (Solove, 2006, p. 519). The collection of personal information enables companies to use the information for marketing purposes, for example, in order to target offers more accurately to individuals’ interests (Culnan & Armstrong, 1999; Wang et al., 2016). Secondary use is described as an asymmetry of knowledge, because individuals are exposed to the uncertainty that they are likely to know little or nothing about the circumstances under which their personal information is captured, sold, or processed, which creates “a sense of powerlessness and vulnerability” (Solove, 2006, p. 520). One prominent example of secondary use of personal information is the recent Facebook privacy scandal, where approximately 87 million Facebook users’ data were collected by political consulting firm Cambridge Analytica without the users’ explicit consent to access their data . As a consequence, user growth on Facebook declined, for example, 3 million users in Europe abandoned Facebook, and Facebook shares decreased by 19%, which equaled a decline of $119 billion .
We choose the MUIPC construct as the focal variable of our study because our main interest are app permission requests and thus we focus on users in the mobile environment. Xu, Gupta et al. (2012, p. 13) arguably propose that “consumers’ concerns for information privacy are not only different but more aggravated in the mobile environment”. To that end, MUIPC is considered to be more suitable and a better-targeted instrument to address privacy concerns of mobile users (Keith, Babb, & Lowry, 2014; Lom, Thoo, Sulaiman, & Adam, 2018). The MUIPC instrument has been used in various studies. For example, Chen and Li (2017) conducted a survey with 284 mobile users and found that MUIPC has a significant impact on the intention to adopt security defensive software. Keith et al. (2014) designed a social geo-caching game, which they used for a field experiment with 568 participants to examine longitudinal behavior of actual information disclosure using the MUIPC instrument. Further studies use MUIPC to analyze the effects of privacy concerns on the sensitivity of mobile fitness data (Vitak, Liao, Kumar, Zimmer, & Kritikos, 2018), or address the moderating role of MUIPC in a mobile advertising context  and regarding the effect of app value as a privacy trade-off for mobile app downloads . The MUIPC instrument has also been used very recently in a study by Belanger and Crossler (2019), in which protective behaviors on mobile devices are in the focus of their analysis.
262
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Trust
# 2. Antecedents of information privacy concerns
Since our aim is to investigate the influence of app permission concerns on mobile users’ information privacy concerns, we draw on the APCO model, which provides positivist privacy researchers with an overarching macro model that summarizes relationships of antecedents and outcomes of privacy concerns . The APCO model is considered to be subject to a continuous process of optimization including “an expanded set of antecedents as well as an exhaustive set of outcomes,” whereby the “ultimate objective should be a macro model that will prove useful across disciplines and contexts” (Smith et al., 2011, p. 1008). Following this recommendation, we present an APCO model in a mobile context in Fig. 1 with a focus on antecedents including prior privacy experience, computer anxiety, and perceived control, as well as app permission concerns as an antecedent of privacy concerns as the main focus of our study.
The APCO model suggests that privacy-related antecedents usually involve individual traits or contextual factors . Individual traits refer to personality differences such as introversion versus extroversion or independent-self versus interdependent-self, whereas contextual factors describe the specific context that the factors depend on such as the industry to which an organization belongs or different types of information with different levels of sensitivity . In our study, we focus on individual traits, of which our main focus are app permission concerns. We suggest that other relevant individual factors for mobile users’ privacy concerns regard prior privacy experience (privacy issues with mobile apps), computer anxiety (continuing automation through the ubiquity of mobile devices), and perceived control (privacy settings to control information retrieval through mobile apps). Due to the focus of our study, we view the APCO model from a mobile perspective and note that while prior privacy experience has been depicted in prior APCO models , we integrate computer anxiety, perceived control, and app permission concerns as new relationships; whereby, computer anxiety and perceived control have been established in prior studies (Stewart & Segars, 2002; Xu, Gupta et al., 2012). In order to enable a comparison of app permission concerns with other relevant antecedents of privacy concerns, we refer to prior privacy experience, computer anxiety, and perceived control, which have been suggested to be important predictors in the information privacy literature (Dinev et al., 2015; Smith et al., 2011, 1996; Stewart & Segars, 2002; Xu, Gupta et al., 2012).
With regard to prior privacy experience, Smith et al. (1996, p. 186) describe that “individuals who had been exposed to, or been the victim of, personal information misuses should have stronger concerns regarding information privacy”. In this regard, a distinction is made between personal experiences and indirect experiences, e.g., in the form of media messages about online privacy risks, which can be as effective as direct experiences because such messages may contain self-relevant information that exposes individuals’ personal privacy risks in online environments (Cho, Lee, & Chung, 2010; Smith et al., 1996; Xu, Gupta et al., 2012). Computer anxiety is defined as “the tendency of individuals to be uneasy, apprehensive, or fearful about current or future use of computers” (Stewart & Segars, 2002, p. 44). Further, Thatcher and Perrewé (2002, p. 384) relate computer anxiety to “fears about the implications of computer use such as the loss of important data or fear of other possible mistakes”. Such loss of important data can entail personal information that is tracked by using mobile applications, which may motivate mobile users “to avoid potential harm arising from ambiguous threat” (Yin, Bond, & Zhang, 2014, p. 542). In our context, mobile users could avoid potential harm by not accepting app permissions that require to access personal information such as mobile users’ location, contacts, and other privacy-related data. The third antecedent, perceived control, refers to “perceived control over personal information as an individual’s belief about the presence of factors that may increase or decrease the amount of control over the release and dissemination of personal information” (Xu, Gupta et al., 2012, p. 1346). Such factors may refer to consumers’ choices about the amount of information collected, e.g., through opt-in and opt-out options (Caudill & Murphy, 2000). For example, in the context of location-based services, users are given the choice to turn off the location tracking from their mobile devices, and thus, opt out from having their personal information transmitted to the service provider. Finally, we add app permission concerns as a new antecedent, which we argue is becoming more and
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Antecedents
# Privacy Concerns
# Outcomes
more important for information privacy concerns regarding the rapid growth of mobile apps and, subsequently, increasingly excessive app permissions. The justification for this addition will be provided in the next section, where we develop our hypotheses related to mobile users’ information privacy concerns.
# 3. Research model and hypothesis generation
Based on the APCO model, we present our research model in Fig. 2, which includes antecedents of information privacy concerns, i.e., prior privacy experience, computer anxiety, perceived control, and app permission concerns, which we propose as an additional antecedent in a mobile user context. Privacy concerns are implemented in the model in the form of mobile users’ information privacy concerns (MUIPC), which are formed by the dimensions of perceived surveillance, perceived intrusion, and secondary use of personal information. Finally, outcomes of privacy concerns are depicted through the intention to accept app permissions.
Considering the mobile context, MUIPC is in the heart of our research model, with prior privacy experience, computer anxiety, perceived control, and app permission concerns as its predictors. Prior privacy experience has been found to be a predictor of information privacy concerns in previous studies (Smith et al., 1996; Xu, Gupta et al., 2012; Xu, Gupta et al., 2012), and we expect that mobile users will have similar experiences with privacy-related issues, as recently supported by a study on mobile privacy concerns by Belanger and Crossler (2019). As such, mobile users will have stronger concerns regarding information privacy once their personal information has been misused in the past or they have heard or read about the use and potential misuse of the information collected from the Internet or through mobile applications. In such cases, mobile users perceive being a victim of personal information misuse, such as in the Facebook/Cambridge Analytica case described earlier, which leads to an increase of information privacy concerns (Borena, Belanger, Ejigu, & Anteneh, 2015; Zlatolas, Welzer, Heričko, & Hölbl, 2015). Thus, we propose the following hypothesis:
H1. Prior privacy experience positively influences mobile users’ information privacy concerns.
As previous studies have shown the impact of computer anxiety on information privacy concerns (Osatuyi, 2015; Stewart & Segars, 2002), we further anticipate that MUIPC will be influenced by computer anxiety. The construct of computer anxiety suggests that it is formed in response to perceived threats from a technology, which leads individuals to experience tension when exposed to computers (Brown, Fuller, & Vician, 2004; Kummer, Recker, & Bick, 2017). Since computer anxiety refers to the loss of important data or fear of other possible mistakes (Thatcher & Perrewé, 2002), we reason that mobile users’ computer anxiety will significantly affect their privacy concerns due to the high degree of sensitive data such as location information, contacts, photos, and other user-related data, which is transmitted through mobile devices. As computer anxiety increases, users may feel uncomfortable with excessive app permission requests and privacy concerns will increase. Therefore, we posit the following hypothesis:
H2. Computer anxiety positively influences mobile users’ information privacy concerns.
With regard to perceived control, we propose that mobile users will have similar fears about a potential misuse of personal data, e.g., through mobile apps that request access to users’ location, although the information is not required by the app. In this regard, app stores allow mobile users to control the amount of personal information. For example, Apple changed the privacy settings with the release of iOS 6, which gives mobile users a higher amount of control over their personal information. The change implied that mobile users can turn off access to contacts, calendars, reminders, photos, Bluetooth sharing, as well as access to Twitter and Facebook accounts. Before this change, users were only allowed to turn off access to location. Later versions of iOS allowed mobile users to control further categories such as opting out of access to the microphone and built-in camera of mobile devices. For Android 5 or lower, it was not possible to control individual app permissions. Google also gave users more control over permissions with the release of Android 6. App stores and providers more and more face the challenge of considering privacy concerns of their users and implement privacy assurance approaches to alleviate those concerns, of which opt-out mechanisms are one such approach. In IS research, perceived control has been found to influence information privacy concerns, for example, in a study by Xu, Teo et al. (2012) or in another study by Wang et al. (2016). Several studies suggest that low levels of perceived control heightens individuals’ risk perceptions, which in turn reduces their capabilities to affect changes in the environment in a desired direction (Du, Keil, Mathiassen, Shen, & Tiwana, 2007; Lang, Wiesche, & Krcmar, 2018). In a mobile environment, this implicates that users will not feel empowered to control their personal information, when app providers
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
do not provide them with possibilities such as turning the location of an app on and off, which will result in growing privacy concerns for users (Lang et al., 2018; Xu, 2007; Xu, Gupta et al., 2012). Based on these lines of logic, we propose the following hypothesis:
# H3. Perceived control negatively influences mobile users’ information privacy concerns.
In addition to prior privacy experience, computer anxiety, and perceived control, we propose app permission concerns as an antecedent of MUIPC. In a recent study by Gu et al. (2017), two factors related to app permission requests have been found to have a significant impact on information privacy concerns: (1) permission sensitivity in terms of the risk level of app permission requests (for example, “access to the vibrator” as a low-risk permission request, and “access to location information” as a high-risk permission request), and (2) permission justification regarding how collected information is used (for example, the justification for “access to the vibrator” is to “remind users when there is a new announcement”). While permission sensitivity and justification relate to distinct characteristics and designated purposes of app permission requests, in our study we focus on app permission requests that relate to the growing collection of personal information through mobile apps per se, which can result in the excessive collection of data and lead to information privacy concerns. Excessive app permission requests that “go beyond the necessary function of the app” (Harris et al., 2016, p. 445) are considered to be less likely accepted by mobile users due to privacy concerns about their personal information (Chin, Harris, & Brookshire, 2018). For example, it has been reported that more than 100,000 apps in Google’s Play Store collected mobile users’ data that was not consistent with their stated functions such as unnecessary location tracking or excessive access to contact lists . We integrate app permission concerns in our research model for two reasons: first, in order to measure the impact of app permission concerns on MUIPC regardless of whether mobile users perceive permission requests to be sensitive or justified; and second, in order to compare app permission concerns to other privacy-related antecedents, i.e., prior privacy experience, computer anxiety, and perceived control. We hypothesize that growing concerns for app permission requests will lead to an increase of users’ overall discomfort about their privacy. Thus, we propose the following hypothesis:
# H4. App permission concerns positively influence mobile users’ information privacy concerns.
Finally, following Wottrich et al.’s (2018) recent findings, we expect that a higher degree of privacy concerns will lead to the outcome that requested app permissions will be less likely accepted. We further base the hypothesis of the effect of privacy concerns on intention on numerous other studies (for example, Gu et al., 2017; Osatuyi, 2015; Smith et al., 1996; Stewart & Segars, 2002; Xu, Gupta et al., 2012). It is suggested that “individuals with higher levels of concern about information privacy practices may be more likely in the future to refuse to participate in activities that require the provision of personal information” (Smith et al., 1996, p. 187). We reason that as privacy concerns increase, users will less likely intent to accept app permissions, which will eventually lead to a decline to install an app. Since app permission acceptance usually involves the provision of personal information, we present the following hypothesis:
# H5. Mobile users’ information privacy concerns negatively influence the intention to accept app permissions.
Since we are not actually measuring an action, we refer to one well-known theory, the Theory of Reasoned Action (TRA) (Ajzen & Fishbein, 1980), which explains that one’s intention to act actually leads to an action. Numerous studies have demonstrated this relationship in prior research including several studies in an information privacy context (Belanger & Crossler, 2019; Keith, Thompson, Hale, & Greer, 2012; Lowry, Cao, & Everard, 2011; Pavlou, Liang, & Xue, 2007; Wang & Herrando, 2019). Hence, we presume that with increasing intentions, there will be a growth of users’ actual acceptance of app permissions.
# 4. Research design and measurements
To test the proposed hypotheses, we designed an online survey and recruited participants from an online social networking website. Due to accessibility, we targeted participants from the United States. We offered incentives in the form of three $50 Amazon gift cards, and participation in the survey was completely voluntary. In survey methodology, it is common practice to offer incentives in exchange for survey participation . We recruited participants by posting announcements, which provided background information about the study. To reduce bias possibility regarding self-selection among survey respondents, we did not disclose in the announcements that privacy concerns were the focus of our study. In the announcements, we asked participants to give their opinion about a mobile social networking app. The subjects could easily participate by using the URL provided in the posting. A total of 918 subjects participated, with 775 producing usable data. Of the 775 participants, 68% were female, 39% were below 20 years and 36% were between 21 and 30 years. Most of the participants were from Georgia (7%), Pennsylvania (6%), and Texas (4%), 59% were students and 25% were employed, and mainly used Android (31%) or iOS (66%). A complete list of participant profiles is provided in Appendix A.
For the operationalization of the latent variables of our research model, we measured the core constructs using reflective multiple-item scales, drawn from pre-validated measures where possible. For the antecedents, we measured prior privacy experience with items adapted from Xu, Gupta et al. (2012) using a 7-point rating scale, which ranged from “not at all” to “very often”. Computer anxiety was measured with a 7-point Likert scale from “strongly disagree” to “strongly agree” adapted from Stewart and Segars (2002), and perceived control with a 7-point rating scale from “no control” to “full control” adapted from Xu, Teo et al. (2012). To measure app permission concerns, we used a 7-point Likert scale ranging from “strongly disagree” to “strongly agree”, which we adapted from Smith et al. (1996) who originally used the scale in a context where companies collected personal information from individuals. Their items were adapted to our mobile user context, more specifically, to our context where mobile users are requested to accept or decline app permissions. In order to allow participants to make sense of app permissions being requested, we presented a scenario in which a hypothetical social networking app required access to various types of information, of which three most common app permissions were presented: location, contacts, and photos. The scenario is provided in Appendix B. For the MUIPC construct, we used 7-point Likert scales ranging from “strongly disagree” to “strongly agree” for the dimensions of perceived surveillance (adapted from Xu, Gupta et al., 2012), perceived intrusion (Xu, Dinev, Smith, & Hart, 2008), and secondary use of personal information . For the outcomes, we measured intention to accept app permissions using a 7-point semantic differential scale with items adapted from Malhotra et al. (2004), who originally used the scale in an Internet user context. The survey instrument is provided in Appendix C.
# 5. Data analysis and results
We conducted partial least squares structural equation modeling (PLS-SEM) with SmartPLS to analyze the collected data. All indicators were modeled as being reflective of their respective constructs. The measurement items loaded between 0 and 0 on their respective constructs, therefore exceeding the recommended threshold of 0 (Hair, Hult, Ringle, & Sarstedt, 2017) and the minimum criteria of 0 , thus demonstrating adequate indicator reliability and convergent validity. The internal consistency of the scales showed composite reliability (CR) ranging from 0 to 0, and Cronbach’s
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
Convergent validity of measurement model.
Notes: PPE = Prior privacy experience, CA = Computer anxiety, PC = Perceived control, APC = App permission concerns, PS = Perceived surveillance, PI = Perceived intrusion, SU = Secondary use of personal information, INT = Intention to accept app permissions.
Latent variable correlation matrix.
Notes: PPE = Prior privacy experience, CA = Computer anxiety, PC = Perceived control, APC = App permission concerns, PS = Perceived surveillance, PI = Perceived intrusion, SU = Secondary use of personal information, INT = Intention to accept app permissions; value on the diagonal (bold) is the square root of average variance extracted (AVE).
alpha ranging from 0 to 0, which were exceeding the recommended value for construct reliability of at least 0 , thus meeting criteria for internal consistency. Average variance extracted (AVE) ranged from 0 to 0, exceeding the recommended lower limit of 0 and thus indicating convergent validity (Fornell & Larcker, 1981). Table 1 provides an overview of the convergent validity of the measurement model.
For discriminant validity (Fornell & Larcker, 1981), we analyzed loadings and cross loadings of the measurement model (see Table 2). All items loaded higher on their constructs than any other constructs and the differences were greater than 0.
We further assessed discriminant validity in a latent variable correlation matrix (see Table 3). The square root of the AVE for each construct was larger than the correlation of the construct with any other constructs in the model, which demonstrated discriminant validity (Fornell & Larcker, 1981).
The correlation matrix also helped to determine if any of the correlations were above 0, which would indicate that common method bias (CMB) may exist . The observed correlations were below the 0 threshold (see Table 3). We further assessed CMB ex post through Harman’s single-factor test. All items from the constructs were included in an unrotated exploratory factor analysis (EFA) to determine whether the majority of the variance could be ascribed to one general factor (Lowry & Gaskin, 2014; Podsakoff, MacKenzie, Lee, & Podsakoff, 2003). Harman’s single-factor test in this study produced 27 distinct factors, the largest of which explained only 37% of the variance of the model. Another ex post approach to examine CMB suggests to conduct a full collinearity test in order to ensure that all factor-level variance inflation factors (VIFs) are lower than 3, which is also an indication that a model can be considered free of CMB .
Since the convergent and discriminant validity criteria for the measurement model were met and CMB was not likely to exist in our model, we proceeded with the path coefficient estimations of the PLS-SEM. As suggested by Xu, Gupta et al. (2012), we created a second-order model to assess the structural model for collinearity issues.
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
Path coefficients and effect sizes of the structural model.
Notes: *** p < 0; ** p < 0; * p < 0; Cohen’s f²-statistics = [R²incl. – R²excl.] / [1- R²incl.] with f² ≥ 0 = small effect size, f² ≥ 0 = medium effect size, and f² ≥ 0 = large effect size .
We found PPE and CA have direct positive effects on MUIPC with significance levels of p < 0 and small effect sizes, supporting H1 and H2. As hypothesized, results show that PC has a direct negative effect on MUIPC, supporting H3, however, the significance level decreases from p < 0 (Model 1) to p < 0 (Model 2) when APC is included in the model. Moreover, the small effect size of PC becomes very small after APC is included. Model 2 further reveals that APC has a direct positive effect on MUIPC with a path coefficient of β = 0 at a significance level of p < 0 and a very large effect size (f² = 1). Thus, H4 is supported. Finally, we found MUIPC has a direct negative effect on INT with a path coefficient of β = –0 at a significance level of p < 0, supporting H5. Overall, the percentage of variance explained for MUIPC increases from 18% (Model 1) to 61% (Model 2), when APC is included in the model. Fig. 3 shows the results of the structural equation modeling.
# 6. Discussion
# 6. Discussion of findings
This study aims to clarify the role of app permission requests regarding mobile users’ information privacy concerns compared to prior privacy experience, computer anxiety, and perceived control. Results of a PLS-SEM analysis with 775 respondents indicated that all four antecedents influence users’ privacy concerns, with app permission concerns having a major impact. Through our study, we confirm significant effects of prior privacy experience, computer anxiety, and perceived control on privacy concerns, as previously reported in prior studies (Osatuyi, 2015; Smith et al., 1996; Stewart & Segars, 2002; Xu, Gupta et al., 2012). However, the construct of app permission concerns has approximately twice as much predictive value than the other factors put together to explain mobile users’ overall information privacy concerns. This implies that app permission concerns have an important effect on mobile users’ concerns for information privacy and that researchers should not exclude it from future models. Following Wang et al.’s (2016) suggestion, our findings support the notion that the wired environment is critically different from the mobile environment, which we presume has made another major shift with the rising popularity of mobile apps and growing app permission requests. Accordingly, we suggest that future mobile privacy research should find new ways of alleviating concerns for app permission requests, which will provide practical implications for app stores and providers.
# 6. Contribution to theory
Our study contributes to existing privacy research in several ways. First, our primary contribution is to clarify the role of app permission requests regarding mobile users’ concerns for information privacy. While prior studies have focused on distinct characteristics of app permission requests such as permission sensitivity, justification, or desensitization , in this research, we analyze mobile users’ concerns for app permission requests per se and the impact on their overall information privacy concerns. While Gu et al. (2017) found sensitivity and justification to be significantly influencing privacy concerns, in Harris et al.’s (2016) study, desensitization of excessive permission requests had no significant impact on risk perceptions to install an app. The insights from these studies support the assumption that app providers should take the sensitivity of app permissions into account and provide reasonable justification whenever permissions are requested; however, users do not seem to become desensitized to excessive permissions, and our findings support that assumption given the major impact of app permission concerns on mobile users’ privacy concerns. From this, we suggest that future mobile privacy research can build on our findings and extend the theory on privacy by seeking opportunities to mitigate app permission concerns, which will eventually further extend contributions to mobile users’ information privacy concerns.
Second, we respond to Smith et al.’s (2011) call for research to investigate an expanded set of antecedents across contexts in the APCO model. We chose the mobile environment as the context of our study and while prior privacy experience was introduced in prior APCO models , we integrated further factors in our mobile-related APCO model including computer anxiety and perceived control drawn from prior privacy studies (Stewart & Segars, 2002; Xu, Gupta et al., 2012), as well as app permission concerns as a new antecedent. Our study extends the literature by proposing these factors as antecedents in the APCO model from a mobile perspective, because with the growing popularity and ubiquity of mobile apps there is not only an increase of privacy issues with mobile apps, but there is also a growing concern for the continuing automation which induces anxiety, an ambiguity of privacy settings leading to a loss of control, and an incremental increase of excessive app permission.
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Antecedents
# Privacy Concerns
# Outcomes
Path significance: m*p < 0
Based on our findings, which suggest that the construct of app permission concerns is the most important antecedent of mobile users’ privacy concerns, it would be important for mobile privacy researchers to include app permission concerns in the examination of antecedents of privacy concerns in future mobile-related APCO models.
# 6. Implications for practice
From a practical perspective, app stores and providers should be alarmed that unnecessary and excessive app permission requests have a strong effect on users’ privacy concerns, which can prevent users from installing mobile apps or make them feel uncomfortable with the result being that they uninstall an app . As a consequence, app providers should ensure that they access personal information stored on mobile devices only if necessary and justified with value-added services, such as location tracking due to navigation purposes. As per our results show, app permission concerns have a highly significant impact on mobile users’ overall information privacy concerns. Considering the large effect of app permission concerns, app providers should reduce permission requests to a required minimum. Due to this large effect, we further suggest that enhancements of the design and presentation of app permission requests are required to respond to the ever-growing privacy concerns of mobile users. For example, the ambiguity and uncertainty of the safety and necessity of app permissions could be resolved by user-generated ratings, which have become ubiquitous and influential on the Internet and the mobile app market (Chang, Ku, & Chen, in press; Gao, Greenwood, Agarwal, & McCullough, 2015; Liu, Au, & Choi, 2014), and which could also help to illuminate privacy assurances of mobile services. Results of this study lead to the recommendation that the mitigation of mobile users’ privacy concerns is important more than ever due to the rapid growth of mobile apps and excessive app permission requests as a consequence thereof.
# 7. Conclusion
This study presented an empirical analysis of the influence of prior privacy experience, computer anxiety, perceived control, and app permission concerns on mobile users’ overall information privacy concerns. While prior privacy experience, computer anxiety, and perceived control had a significant impact on mobile users’ information privacy concerns, the predictive value of app permission concerns was approximately twice as much than the other factors put together. Our findings suggested that existing designs of app permission requests are problematic such that mobile users refuse to disclose their personal information mainly due to concerns for app permission requests. App stores and providers can leverage the findings of this study and rethink the design features of app permission requests to alleviate mobile users’ concerns for app permission requests, which in turn decreases users’ overall information privacy concerns, and eventually leads to an increase of the intention to accept app permissions.
# 7. Limitations
Our study is subject to the following limitations. First, the survey was conducted with participants from the United States. While various states within the United States were broadly covered in our study, a survey in other countries may lead to different results. According to Hofstede’s cultural dimension index, the United States is a highly individualist culture (Hofstede, Hofstede, & Minkov, 2010). Thus, mobile users from the United States might have higher privacy concerns due to individual interests compared with users from collectivist cultures. Second, most of our participants were female students and up to the age of 30 years. Correlations of the demographic variables with other variables were very low in our sample, which indicated that there were no confounding effects. Nevertheless, other demographic user groups might present different concerns for information privacy. Third, we collected data through an online survey, which is liable to a self-selection bias (Kim, Lee, Han, & Lee, 2002). During participant recruiting, we asked participants to complete a survey about a social networking app. We did not mention that the focus of the survey is on information privacy concerns. Hence, the decision of the subjects to participate in the survey should not be related to their information privacy concern (Hui, Teo, & Lee, 2007). Fourth, for our scenario, we chose three most common app permissions: location, contacts, and photos. We acknowledge that these app permissions may be perceived as highly sensitive by mobile users compared to other permissions such as access to the vibrator or reminders. While perceived permission sensitivity has been analyzed in prior studies , in our study, we lay the focus on the overall impact of app permission concerns on mobile users’ privacy concerns; however, we do suggest that other app permissions than location, contacts, and photos may lead to different results.
268
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# 7. Future research directions
Against the backdrop of increasing privacy-related challenges for app stores and providers, our findings provide a basis for future research studies on mobile users’ concerns for information privacy with a focus on app permission requests. Following the investigation by Gu et al. (2017) on permission sensitivity and justification, future research could involve experimental surveys to evaluate the impact of such ratings on app permission concerns. For example, different scenarios could be presented in which app permissions are requested with various rating options. Questions could revolve around how safe it is for mobile users to share their personal information with the app and how necessary it is to request certain app permissions. We expect that further research on these proposed investigations will further contribute to a better understanding of mobile users’ information privacy concerns.
It would be insightful to learn if the influence of permission requests on privacy concerns is alleviated the more popular or the more positive the reputation of an app is. Another focus of interest in this regard are privacy assurance approaches such as privacy statements, which ensure user privacy and data protection (Sutanto et al., 2013; Xu, Gupta et al., 2012). We suggest further research to analyze whether such privacy statements lose their effect the more app permissions are perceived to be of concern. Within these settings, we further suggest to consider perceived control in a future analysis, because control might provide a reinforcement or substitution effect, when (a) the popularity or (b) the app permissions are highly sensitive, (c) app permission requests are poorly or not at all justified, or (d) privacy statements on how safe the access to personal information is, are missing.
# Appendix A. Participant profiles
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Appendix B. Scenario
We provided a scenario to all participants in the survey. They were told that an online social networking service is providing a mobile application called “M-Networking”, and that their opinion about the app was being solicited. The survey included the following scenario: “An online social networking service provides M-Networking, which is a mobile application to connect with other users such as family, friends, and colleagues. Suppose you are considering whether you will install such M-Networking service on your mobile device, the app is requesting the following permissions: location (approximate location (network-based), precise location (GPS and network-based), and GPS access), contacts (read your contacts, modify or delete your contacts, and create contacts), and photos (access your photos, modify or delete your photos, and add photos)”.
# Appendix C. Survey instrument
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Perceived intrusion
If I would accept these app permissions…
PS2: I would be concerned that the app is collecting too much information about me.
PS3: I would be concerned that the app may monitor my activities on my mobile device.
PI1: I feel that as a result, others would know about me more than I am comfortable with.
PI2: I believe that as a result, information about me that I consider private would be more readily available to others than I would want.
PI3: I feel that as a result, information about me would be out there that, if used, would invade my privacy.
# Secondary use of personal information
If I would accept these app permissions…
SU1: I would be concerned that the app may use my personal information for other purposes without notifying me or getting my authorization.
SU2: I would be concerned that the app may use my information for other purposes.
SU3: I would be concerned that the app may share my personal information with other entities without getting my authorization.
# Intention to accept app permissions
Given these app permission requests, specify the extent to which you would accept these app permissions.
INT1: unwilling–willing
INT2: unlikely–likely
INT3: not probable–probable
INT4: impossible–possible
# K. Degirmenci
# International Journal of Information Management 50 (2020) 261–272
# Manifestations, cultural influences, and its effect on the adoption of sensor-based technology in German and Australian hospitals.
Information & Management, 54(1), 73–89. https://doi.org/10/j.im.
Lang, M., Wiesche, M., & Krcmar, H. (2018). Perceived control and privacy in a professional cloud environment. Paper Presented at the Hawaii International Conference on System Sciences.
Laufer, R. S., & Wolfe, M. (1977). Privacy as a concept and a social issue: A multi-dimensional developmental theory. Journal of Social Issues, 33(3), 22–42. https://doi.org/10/j-4560.tb01880.x.
Lienhard, K., & Legner, C. (2015). The anatomy of context-aware mobile patient monitoring. Paper Presented at the International Conference on Information Systems.
Lindell, M. K., & Whitney, D. J. (2001). Accounting for common method variance in cross-sectional research designs. The Journal of Applied Psychology, 86(1), 114–121.
Liu, C. Z., Au, Y. A., & Choi, H. S. (2014). Effects of freemium strategy in the mobile app market: An empirical study of Google Play. Journal of Management Information Systems, 31(3), 326–354. https://doi.org/10/07421222.
Lom, H. S., Thoo, A. C., Sulaiman, Z., & Adam, S. (2018). Moderating role of mobile users’ information privacy concerns towards behavioural intention and use behaviour in mobile advertising. Advanced Science Letters, 24(6), 4259–4264. https://doi.org/10/asl.
Lowry, P. B., Cao, J., & Everard, A. (2011). Privacy concerns versus desire for interpersonal awareness in driving the use of self-disclosure technologies: The case of instant messaging in two cultures. Journal of Management Information Systems, 27(4), 163–200. https://doi.org/10/MIS0742-1222270406.
Lowry, P. B., & Gaskin, J. E. (2014). Partial least squares (PLS) structural equation modeling (SEM) for building and testing behavioral causal theory: When to choose it and how to use it. IEEE Transactions on Professional Communication, 57(2), 123–146. https://doi.org/10/TPC.
Malhotra, N. K., Kim, S. S., & Agarwal, J. (2004). Internet users’ information privacy concerns (IUIPC): The construct, the scale, and a causal model. Information Systems Research, 15(4), 336–355. https://doi.org/10/isre.
Neate, R. (2018). Over $119bn wiped off Facebook’s market cap after growth shock. Retrieved from The Guardian https://www.theguardian.com/technology/2018/jul/26/facebook-market-cap-falls-109bn-dollars-after-growth-shock.
Osatuyi, B. (2015). Is lurking an anxiety-masking strategy on social media sites? The effects of lurking and computer anxiety on explaining information privacy concern on social media platforms. Computers in Human Behavior, 49, 324–332. https://doi.org/10/j.chb.
Pavlou, P. A., Liang, H., & Xue, Y. (2007). Understanding and mitigating uncertainty in online exchange relationships: A principal–agent perspective. MIS Quarterly, 31(1), 105–136. https://doi.org/10/25148783.
Podsakoff, P. M., MacKenzie, S. B., Lee, J.-Y., & Podsakoff, N. P. (2003). Common method biases in behavioral research: A critical review of the literature and recommended remedies. Journal of Applied Psychology, 88(5), 879–903. https://doi.org/10/0021-9010.
Robertson, J. (2012). Android apps collect too much user data, researcher says. Technology: Security. Retrieved from The Sydney Morning Herald https://www.smh.com.au/technology/android-apps-collect-too-much-user-data-researcher-says-20121102-28oie.html.
Selya, A. S., Rose, J. S., Dierker, L. C., Hedeker, D., & Mermelstein, R. J. (2012). A practical guide to calculating Cohen’s f2, a measure of local effect size, from PROC MIXED. Frontiers in Psychology, 3(111), 1–6. https://doi.org/10/fpsyg.
Smith, H. J., Dinev, T., & Xu, H. (2011). Information privacy research: An interdisciplinary review. MIS Quarterly, 35(4), 989–1015. https://doi.org/10/41409970.
Smith, H. J., Milberg, S. J., & Burke, S. J. (1996). Information privacy: Measuring individuals’ concerns about organizational practices. MIS Quarterly, 20(2), 167–196. https://doi.org/10/249477.
Solove, D. J. (2006). A taxonomy of privacy. University of Pennsylvania Law Review, 154(3), 477–560. https://doi.org/10/40041279.
Stewart, K. A., & Segars, A. H. (2002). An empirical examination of the concern for information privacy instrument. Information Systems Research, 13(1), 36–49. https://doi.org/10/isre.
Sutanto, J., Palme, E., Tan, C.-H., & Phang, C. W. (2013). Addressing the personalization–Privacy paradox: An empirical assessment from a field experiment on smartphone users. MIS Quarterly, 37(4), 1141–1164. https://doi.org/10/misq/2013/37.
Thatcher, J. B., & Perrewé, P. L. (2002). An empirical examination of individual traits as antecedents to computer anxiety and computer self-efficacy. MIS Quarterly, 26(4), 381–396. https://doi.org/10/4132314.
Vitak, J., Liao, Y., Kumar, P., Zimmer, M., & Kritikos, K. (2018). Privacy attitudes and data valuation among fitness tracker users. In G. Chowdhury, J. McLeod, V. Gillet, & P. Willet (Vol. Eds.), Transforming digital worlds: Vol. 10766, (pp. 229–239). Cham, Switzerland: Springer. https://doi.org/10/978-3-319-78105-1_27.
Wang, T., Duong, T. D., & Chen, C. C. (2016). Intention to disclose personal information via mobile applications: A privacy calculus perspective. International Journal of Information Management, 36(4), 531–542. https://doi.org/10/j.ijinfomgt.
Wang, Y., & Herrando, C. (2019). Does privacy assurance on social commerce sites matter to millennials? International Journal of Information Management, 44, 164–177. https://doi.org/10/j.ijinfomgt.
Wottrich, V. M., van Reijmersdal, E. A., & Smit, E. G. (2018). The privacy trade-off for mobile app downloads: The roles of app value, intrusiveness, and privacy concerns. Decision Support Systems, 106, 44–52. https://doi.org/10/j.dss.
Xu, H. (2007). The effects of self-construal and perceived control on privacy concerns. Paper Presented at the International Conference on Information Systems.
Xu, H., Dinev, T., Smith, H. J., & Hart, P. (2008). Examining the formation of individual’s privacy concerns: Toward an integrative view. Paper Presented at the International Conference on Information Systems.
Xu, H., Gupta, S., Rosson, M. B., & Carroll, J. M. (2012). Measuring mobile users’ concerns for information privacy. Paper Presented at the International Conference on Information Systems.
Xu, H., Teo, H.-H., Tan, B. C. Y., & Agarwal, R. (2009). The role of push-pull technology in privacy calculus: The case of location-based services. Journal of Management Information Systems, 26(3), 135–173. https://doi.org/10/MIS0742-1222260305.
Xu, H., Teo, H.-H., Tan, B. C. Y., & Agarwal, R. (2012). Effects of individual self-protection, industry self-regulation, and government regulation on privacy concerns: A study of location-based services. Information Systems Research, 23(4), 1342–1363. https://doi.org/10/isre.
Yin, D., Bond, S. D., & Zhang, H. (2014). Anxious or angry? Effects of discrete emotions on the perceived helpfulness of online reviews. MIS Quarterly, 38(2), 539–560. https://doi.org/10/misq/2014/38.
Zhang, D., Adipat, B., & Mowafi, Y. (2009). User-centered context-aware mobile applications―The next generation of personal mobile computing. Communications of the Association for Information Systems, 24(3), 27–46. https://doi.org/10/1cais.
Zlatolas, L. N., Welzer, T., Heričko, M., & Hölbl, M. (2015). Privacy antecedents for SNS self-disclosure: The case of Facebook. Computers in Human Behavior, 45, 158–167. https://doi.org/10/j.chb.
272