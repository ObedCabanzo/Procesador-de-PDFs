# CHI 2019 Paper
# “Think secure from the beginning”: A Survey with Software Developers
Hala Assal
School of Computer Science
Carleton University
Ottawa, ON, Canada
HalaAssal@scs.carleton.ca
# ABSTRACT
Vulnerabilities persist despite existing software security initiatives and best practices. This paper focuses on the human factors of software security, including human behaviour and motivation. We conducted an online survey to explore the interplay between developers and software security processes, e.g., we looked into how developers influence and are influenced by these processes. Our data included responses from 123 software developers currently employed in North America who work on various types of software applications. Whereas developers are often held responsible for security vulnerabilities, our analysis shows that the real issues frequently stem from a lack of organizational or process support to handle security throughout development tasks. Our participants are self-motivated towards software security, and the majority did not dismiss it but identified obstacles to achieving secure code. Our work highlights the need to look beyond the individual, and take a holistic approach to investigate organizational issues influencing software security.
# CCS CONCEPTS
- Security and privacy → Software and application security; Human and societal aspects of security and privacy.
# KEYWORDS
Security, Survey, HCI for development, Secure programming
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.
CHI 2019, May 4–9, 2019, Glasgow, Scotland Uk
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5970-2/19/05. . . $15
https://doi.org/10/3290605
Sonia Chiasson
School of Computer Science
Carleton University
Ottawa, ON, Canada
Chiasson@scs.carleton.ca
# ACM Reference Format:
Hala Assal and Sonia Chiasson. 2019. “Think secure from the beginning”: A Survey with Software Developers. In CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019), May 4–9, 2019, Glasgow, Scotland Uk. ACM, New York, NY, USA, 13 pages. https://doi.org/10/3290605
# 1 INTRODUCTION
Software security focuses on the resistance of applications to vulnerabilities exercised through malicious exploitations or unintentional triggers . Best practices and initiatives have been proposed to promote the inclusion of security throughout the Software Development Lifecycle (SDLC) (e.g., ) in part to address such vulnerabilities. However, vulnerabilities persist, impact millions of users , and extend beyond traditional computing systems .
Developers are often blamed for vulnerabilities  and are sometimes viewed as the “weakest link” who just need to do more . However, recent user-centric research has focused on software developers as users who critically need support when dealing with the implementation of software that adequately addresses security .
In this paper, we take a human-centric approach to address an under-investigated research area—the interplay between the developer and the process of managing software security. We focus on understanding how the human actors (e.g., developers) deal with, and influence, this process. Although we do not focus on technologies to support secure software development, this work can help inform the design of these technologies. We note that security vulnerabilities could be unintentional or could be introduced to a system out of malice. In this paper, we focus on supporting developers avoid unintentional vulnerabilities; malicious developers are thus out of the scope of this work. In particular, this paper addresses the following three research questions. RQ1: How does security fit in the development lifecycle in real life? RQ2: What are the current motivators and deterrents to developers paying attention to security? RQ3: Does the development methodology, company size, or adopting Test-Driven Development (TDD) influence software security?
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
To answer these questions, we conducted an online survey study with a representative sample of 123 software developers from North America. The survey focuses on how developers and their teams direct their efforts towards software security, as well as strategies developers employ to deal with security. We also explore developers’ work motivation styles, their motivation towards software security, as well as factors that may deter developers from addressing security.
Our study shows that efforts towards software security vary; in extreme cases, security is consistently disregarded throughout the SDLC but most participants reported at least some attention to it. Development methodology had no significant effects on our results. The use of TDD was most influential, while company size had moderate influence.
In general, our results are promising for software security and suggest that developers do not intentionally disregard it. Our participants have a good understanding of software security and generally oppose statements that imply ignoring or deferring security, even though it is typically not their primary objective . However, our analysis identified systemic barriers to achieving secure code, e.g., the lack of a security plan. This highlights the need to investigate and address organizational issues that lead to insecure practices.
# 2 RELATED WORK
In their overview of the usable security field, Garfinkel and Lipford  highlight the shortage of human factors security research that focuses on software developers. Naiakshina et al.  cautioned that researchers do not have the same expertise in studies with developers as with typical end-users, and they discussed how different study designs can help investigate different research questions. Pieczul et al.  discussed challenges facing usable security research for developers and highlighted the need for deeper understanding of the continuously evolving field of software development.
# Developers’ Abilities and Expertise
Developers and their lack of security education are frequently cited as the reason for vulnerabilities . The assumption is that if developers learned about security, they could avoid vulnerabilities . Some argue the reason might be because security guidelines do not exist or are not mandated by the companies , or that developers might lack the ability  or proper expertise  to identify vulnerabilities.
Baca et al.  found that developers’ general software development experience did not have the expected positive impact on the correctness of identifying vulnerabilities. Oliveira et al.  argued that developers and security education are not the root causes of security vulnerabilities. They explained that throughout their tasks, developers are consumed with solving problems that assume common cases, whereas vulnerabilities are usually unexpected corner cases  that are cognitively-demanding to identify .
# Security Tools and Methodologies
Approaches for improved code security include advocating for the use of Static-code Analysis Tools (SATs) , reducing their false positives , and using innovative methods to assist in vulnerability discovery . However, despite SATs’ benefits , they are not widely used .
Security tool adoption: The company’s policies and its overall security culture are among the main factors for encouraging developers to adopt new security tools . Developers’ positive perception of the usefulness of security to their applications also encourages security tool adoption , whereas tools’ complexity discourages it .
Improving tools’ usability: Smith et al.  proposed an approach for building tools that support developers’ information needs while analyzing vulnerabilities. They identified 17 categories of information that developers seek during the analysis of SAT warnings . These included questions regarding understanding vulnerabilities, attacks that might exploit these vulnerabilities, alternative fixes, and whether a vulnerability is worth fixing .
In-context security: Xie et al.  proposed a tool to remind web developers of secure programming practices in their Integrated Development Environment (IDE). The tool statically analyzes the code and alerts developers of potential issues on-the-spot. Although it does not cover all vulnerability types, usability evaluations (e.g., ) showed promising results in encouraging developers’ attentiveness to security. Focusing on mobile applications, Nguyen et al.  developed an IDE plugin to support Android app developers adhere to and learn about security best practices. Studies suggest that the plugin significantly improves code security regardless of the developer’s experience .
APIs and documentation: The use of Application Programming Interfaces (APIs) is recommended to improve code security . However, further research is needed for improving the design of APIs to reduce vulnerability-causing mistakes  and account for security implications that may be missed by developers . For example, Acar et al.  found usability issues in several cryptographic APIs that can result in compromised code security. In addition, many software security guidance resources available to developers lack helpful concrete examples, fail to address important topics, and some include obsolete advice . This is an unfortunate finding, given that developers often rely on resources that are not necessarily ideal for security . To partially address this, Gorski et al.  integrated context-sensitive security advice in a cryptographic API, which significantly improved the security of code using this API.
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
Overall, researchers have argued for more developer-centric security experiences, e.g., by providing developers with practical security experience in using code analysis tools , facilitating security education in-context of developers’ IDEs , focusing security training on addressing weaknesses in developers’ security knowledge , and facilitating interaction between developers and security experts .
Existing research focuses on helping developers improve their code security by reducing their cognitive load. However, several research gaps remain in addressing the human aspects of software security, such as factors that motivate developers to value and address security. In this paper, we take a human-centric approach to explore developers’ software security strategies and motivation. In addition, we investigate different characteristics that may influence security processes, such as the development methodology, company size, and whether the development team employs TDD.
# 3 METHODOLOGY
We conducted an IRB-approved anonymous online survey with professional software developers using Qualtrics .
# Survey Design
The survey included different types of questions, e.g., multiple choice, Likert-scale, and short answer questions. The survey had two main sections, grouping questions by topic to minimize the cognitive load on participants and allow them to consider the topic more deeply . The first section covered demographic information and investigated participants’ general work motivation through the established 18-item Work Extrinsic and Intrinsic Motivation Scale (WEIMS) . The second section focused on software security, specifically participants’ efforts towards security, their strategies for handling security, and their opinions about their teams and experiences with security issues, as well as software security motivations and deterrents. In addition, we asked participants to describe what it means to them “to include security into the development process” to capture their original understanding of software security. However, to ensure that participants have a baseline understanding of software security, we then provided a brief explanation of software security and how it differs from security functions. Survey questions were informed by our previous qualitative research . More details about the questions and format are available in Section 5, along with the corresponding results.
# Testing the Survey Tool
We followed Dillman’s recommended three-stage process  to pre-test the survey. First, the survey was reviewed by colleagues and experts in the field to uncover potential misunderstandings or unexpected outcomes. Next, we discussed the survey’s clarity and motivation with developers. Finally, we performed pilot-testing with 11 developers to identify any flaws in the survey and to determine whether it is of appropriate length.
# Participant Recruitment
Recruiting developers is one of the challenges of this type of research . To reach a wide range of developers, we recruited through two methods. (1) Through Qualtrics’  paid service; we paid Qualtrics $32 USD per participant for recruitment and data collection. Participants received the equivalent of $6 in gifts (e.g., SkyMiles, gift cards). (2) Through announcing the survey to our professional and industry contacts; participants received a $10 Amazon gift card as compensation.
# Data Quality
We took multiple precautions to ensure data quality. We provided participants with a description of software security to avoid confusion and differences in interpretation. Participants were prevented from progressing with the survey until they showed understanding of our description of software security. We discarded responses with less than seven minutes for survey completion time, and responses with invalid data, e.g., gibberish in the open-ended question or conflicting responses.
# Participant Demographics
Through the different channels, we recruited a total of 140 participants, and discarded 17 for quality issues. The data reported herein is from the remaining 123 valid responses. Average survey completion time was 24 minutes (Md = 17). Participant demographics are available in Table 1. Participants are currently working in development in Canada (n = 63, 51%) or the US (n = 60, 49%). They employ different development methodologies and develop a wide range of applications. The average company age where participants work is 41 years (Md = 20). Our dataset includes a good range of established companies: 25th and 75th percentile is 15 and 50 years, respectively.
# 4 SURVEY ANALYSIS
All the results presented in this paper represent participants’ self-reported behaviours and attitudes. Data analysis for the open-ended question followed an inductive approach. The first author performed open coding, and both authors regularly discussed emerging themes and common patterns in the data. Quantitative data analysis used SPSS Statistics. All statistical tests assumed p <  as a significant level, unless Bonferroni-correction was applied.
All survey questions were optional, thus missing values may exist. These are ignored from the analysis, in which cases we indicate the actual number of data points (participants) when reporting the results.
# Factor Analysis
We used factor analysis to analyze participants’ security strategies, motivators, and deterrents. Principal axis factor analysis enabled us to group closely related information, thus, reducing the set of variables into a smaller set (factors), while retaining the majority of the original information .
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
Within and between subjects statistical tests on strategies, motivations, and deterrents all used the resultant factors. As recommended, we retained variables with absolute factor loadings greater than 0 . For all factor analyses, we used the Kaiser Meyer-Olkin (KMO) measure  to verify the sampling adequacy.
# 5 RESULTS
# Developers’ Work Motivation
To explore participants general work motivation, we generated the Work Self-Determination Index (W-SDI)  from the WEIMS. A positive W-SDI indicates a self-determined motivation profile, whereas a negative score indicates non-self determination . Results indicate that our participants do not lack motivation with respect to performing their job; the vast majority (89%) exhibited self-determined motivation profiles (W-SDI > 0).
sw isn’t interesting target we have security procedures security is important
0 20 40 60 80 100 % of participants strongly disagree disagree agree strongly agree
consequences of malicious attacks, and prevent unauthorized access or use of their software or the data it handles. Participants also explained that security should be considered from the earliest stages and throughout the development process. For example, one participant described software security as, “To think about security from the earliest planning phases as possible [...] and continue to focus on security implications throughout the remainder of the development process.” In addition, some participants indicated that security defences should be proactive, and that developers should “think secure from the beginning” and adopt an attacker-mindset. For example, a participant said, “rather than asking how will we achieve ‘this’, you ask how will someone exploit ‘this’. [...] when your processes are done in a proper, security conscious way, as much of the potential harm as possible should be mitigated.” Participants also discussed various methods to ensure software security, such as internal and external audits, security testing, automated checks, code analysis and reviews, thinking about security when writing code, and incorporating security in design. Some participants also discussed the importance of following best practices, using tools and programming languages approved by their organizations, and receiving support from security experts in their organizations.
# Behaviours and Attitudes
Participants indicated on a 4-point Likert scale (1:strongly disagree to 4: strongly agree) their agreement with statements about their teams. As shown in Figure 1, participants generally indicated that their teams believe in the importance of software security and that they have specific procedures in place to address it, even though they mostly do not think that their applications are interesting targets for attackers. All participants, except one, who reported security is not important for their teams also indicated that their software is not an interesting target for attackers.
# Developers’ Mental Models of Software Security
65% of participants had a reasonable understanding of software security. Most participants discussed that software security aims to minimize vulnerabilities, minimize the negative.
# Experiencing Security Issues
On 5-point Likert scales, participants indicated their satisfaction with their teams’ security processes and the likelihood that their software has vulnerabilities. Figure 2 shows that
Paper 289 Page 4
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
In general, participants are satisfied with their team’s handling of software security. However, despite their satisfaction, participants believed that software developed by their team likely contains security issues (Figure 3).
Participants were asked to report whether their software has ever experienced a security issue. More than a third of participants reported at least one security issue. Vulnerable shipped code was most frequently reported (24%) out of the three potential security issues in the survey. Fourteen percent of participants indicated that vulnerabilities were discovered before their software was shipped, and 11% reported their software experienced a security breach. We note that these numbers are not mutually exclusive; some participants (11%) reported multiple security issues.
For participants who reported security issues (n = 43), we explored the long-term reaction to experiencing such issues by the different stakeholders. Although it may be expected that awareness and attitude towards security improves right after experiencing an issue, our data suggests that this effect is longstanding. Figure 4 shows that 79% of participants indicated that experiencing a security issue increased their awareness and concern for security over the long-term. Participants also reported the same effect on other developers in their teams (77%), team leaders (88%), upper management (74%), and users (49%). This implies that experiencing a real threat can help avoid the optimism bias1  and can lead to improved attitudes and behaviours towards security.
Forty-four percent of participants indicated that company security issue(s) did not change their users’ awareness and concern for security. “Users” had the highest percentage of “no change” across the different stakeholders, as shown in Figure 4. This is reasonable given that users are not typically aware of such software security issues unless, e.g., a security breach is publicized or users directly experience the effects.
# We will now discuss our results arranged by research question.
# RQ1: how software security fits in the SDLC.
The survey had several questions exploring development teams’ efforts and strategies towards software security.
# Efforts Towards Security.
Participants reported the percentage of effort directed towards security out of the overall development lifecycle effort. They also reported the percentage of effort out of all security efforts as a percentage for different development stages (design, implementation, developer testing, code analysis, code review, and post-development testing). The total for all stages equaled 100%.
As shown in Figure 5, participants indicated that, on average, 19% (Md = 10%) of their teams’ overall effort in the development lifecycle relates specifically to security tasks. Six participants (5%) indicated that their teams do not spend any effort on security.
We used Friedman’s ANOVA to determine whether the distribution of security efforts significantly differs across the different SDLC stages. As Figure 5 shows, security effort in the implementation stage was significantly higher than in the code analysis, developer testing, code review, and post-development testing stages. Security effort in the design stage was also significantly higher than in the code analysis and code review stages. It is unclear why participants focused their efforts at these two stages; it could be because they try to get it right from the beginning, thus reducing the effort needed during later stages, or it could be because later stages are mainly functionality-oriented.
1Optimism bias is the belief that “misfortune will not strike me” .
Paper 289
Page 5
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
(Figure shows stages that significantly differ in efforts towards security. ∗∗ χ F 2(5) = 78, n = 123. ∗ : p < , ∗∗ : p < )
# Strategies for handling software security (n = 82)
# Strategies to Address Software Security.
Participants rated their agreement with relying on 16 potential software security strategies on a 5-point Likert scale.
As shown in Figure 6, most participants indicated that when fixing a security issue, they rely on support from colleagues who faced similar issues. For security advice, the majority of participants reported relying on those with more experience. More than half also indicated relying on their own personally-devised security checklists to handle security, or on company-wide strategies, e.g., automated checks.
We performed factor analysis to integrate these 16 strategies to a smaller set and found that 12 strategies could be grouped into two factors; four strategies did not conform to any factor (results in Table 2). We named the first resultant factor: company-wide engagement, as it describes how developers rely on their companies’ strategies and support, e.g., relying on the more experienced team members (conforming with previous research ), or using custom tools that handle software security. This factor encompassed nine strategies. The second factor incorporated three strategies and is named: personal strategies, where developers devised their own software security strategies, e.g., having their own mental checklist of issues to consider.
Paper 289
Page 6
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
# personal strategies
# financial rewards[M6]
# experiencing breach[M20]
# company-wide
# engagement
# relevant breach[M19]
# career growth[M5]
# RQ2: Security Motivators and Deterrents
To explore what motivates developers to address software security, we presented participants with a list of 21 potential motivators, as well as 29 statements that could explain reasons for deferring security. Participants ranked their agreement with each statement on a 5-point Likert scale.
# Software Security Motivators
We asked participants “I care about security because...” and presented potential motivations for software security. In addition to the Likert scale, this question had a “not applicable" option in case a motivation did not apply to a participant’s workplace.
As shown in Figure 8, the top six reasons to care about software security are self-driven motivations . Participants are motivated by the challenge or by their own values (e.g., to protect their users). Receiving financial rewards (an external motivation) was reportedly least motivating.
We used factor analysis to combine the 21 motivators into a smaller set (Table 3). Our factor analysis grouped 15 of them into four factors; six motivators did not conform to any particular factor. We named the factors: workplace environment, identifying with security importance, rewards, and perceived negative consequences. Out of the four factors, rewards is the only one representing external motivations . For further analyses, we created a variable for each factor by averaging participants’ responses to all motivators belonging to the factor.
We found statistically significant differences between the four software security motivators (χ F 2(3) = 85, p < ). Pairwise comparisons using Wilcoxon tests with Bonferroni correction were used to follow up this finding. We found that rewards was the least significant motivator compared to workplace environment (T = 1, p < , r = 0), identifying with security importance (T = 1, p < , r = 0), and perceived negative consequences (T = −0, p < , r = −0). In addition, it appears that identifying with security importance is the most motivating factor; it can motivate developers more than perceived negative consequences (T = 0, p < , r = 0) and workplace environment (T = −0, p < , r = −0).
Participants’ software security motivation appears to match their general work motivation pattern. Their top security motivators are all intrinsic and internal motivations .
# Deterrents to Software Security
Participants generally opposed statements that imply deferring or ignoring security, as suggested by the overwhelmingly red and orange chart in Figure 10. The biggest deterrent to software security was the lack of a formal plan or process, followed by participants being unaware of security code-analysis tools.
We could only include data from participants who answered all questions in each factor.
Paper 289
Page 7
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
Our factor analysis combined 18 of the 29 software deterrents into four factors; 11 deterrents did not correspond to any particular factor (Table 4). Our first two factors are security is irrelevant and competing priorities & no plan. These describe how a lack of security can stem from systemic causes within the company or team, such as whether there are consequences for the lack of security, whether security is a priority, and if specific security plans exist. The other two factors, unequipped for security and disillusioned, describe security deterrents on a more personal level, e.g., a lack of support, knowledge, and awareness can deter developers from addressing security, as well as being in a workplace environment that thwarts, rather than nurtures, security efforts.
Considering the four factors, as Figure 11 shows, the two most frequent deterrents to software security were (1) being unequipped for security because of a perceived lack of security.
Paper 289
Page 8
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
# RQ3: EFFECT OF DIFFERENT CHARACTERISTICS ON SOFTWARE SECURITY
In this section, we explore the impact of three main characteristics on software security overall: (1) the development methodology used by participants’ teams, (2) the size of the company where participants work, and (3) whether they perform TDD. Specifically, we explore whether these characteristics influence security efforts, software security strategies, security motivators, or deterrents to software security. We focus on these three characteristics because they were considered as potential influencers on software security in previous literature (e.g., ) or in our previous discussions with software developers and security experts.
Development Methodology. Focusing on the three development methodologies with the highest percentages of participants in our data: Waterfall (22%), Iterative (21%), and Agile development (47%), our analysis using Kruskal-Wallis tests with Bonferroni-correction showed that, contrary to previous literature , the development methodology did not significantly influence teams’ handling of software security. We did not find evidence that the development methodology influenced teams’ overall effort towards software security, nor did it influence their effort per development stage. In addition, it had no influence on software security strategies or deterrents to security. Our results indicated that the development methodology may influence knowledge or the unavailability of necessary tools, and (2) competing priorities & no plan, where security has a lower priority than other aspects of the software and the team lacks specific security plans or procedures.
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
Some security motivations, identifying with security importance (H (2) = 7, p < ), rewards (H (2) = 6, p < ), and perceived negative consequences (H (2) = 6, p < ). However, follow-up pairwise comparisons with Bonferroni-correction were not significant.
# Company Size
Following the classification used in North America , we classified participants’ companies into either Small and Medium Enterprises (SMEs) if the company had fewer than 500 employees, and Large Enterprises (LEs) otherwise. Our dataset contained 49 (40%) participants in SMEs and 74 (60%) in LEs.
Using Mann-Whitney tests, we found no evidence that the company size influenced the percentage of effort on software security, overall or per development stage. In addition, it did not influence participants’ software security strategies.
However, our results show a significant difference in security motivations between SME and LE participants. Being in a workplace environment that nurtures security was more motivating for participants in LEs, compared to those in SMEs (U = 861, n = 76, p < 0, r = −0).
Our results also show that deterrents to software security vary significantly with company size. Specifically, having competing priorities & no plan is significantly more common deterrent to security for participants in SMEs compared to those in LEs (U = 1345, p < 0, r = −0). Likewise, being unequipped for security is a significantly more common deterrent to security for SME participants compared to their counterpart (U = 1413, p < 0, r = −0).
We also performed post-hoc analysis to explore further effects of company size, e.g., whether it had an effect on participants’ behaviours and attitudes towards software security, or whether the company experienced security issues. All the tests were not significant, e.g., we found no difference between SME and LE participants in considering that their applications are interesting targets for attackers (U = 1552, n = 123, p = 0).
# Test-Driven Development (TDD)
Out of the characteristics explored, TDD most influences software security.
Our results show that efforts directed towards software security are influenced by whether the team performs TDD. Participants who perform TDD spend significantly more overall effort on security than those who do not perform TDD (U = 905, n = 114, p < 0, r = −0). Focusing on each SDLC stage, TDD participants spend significantly higher efforts towards security during code analysis than their counterparts (U = 554, n = 114, p < 0, r = −0).
We also found that adopting TDD influences software security strategies. TDD participants rely significantly more on company-wide engagement (U = 397, n = 80, p < 0, r = −0) and on their own personal strategies (U = 506, n = 80, p < 0, r = −0) to handle software security than participants who do not perform TDD.
Finally, our results show that TDD participants are not significantly different than those who do not perform TDD when it comes to security deterrents and the majority of security motivators. However, we found that rewards is a more significant security motivator to TDD participants compared to their counterparts (U = 453, n = 68, p < 0, r = −0).
# 7 DISCUSSION
Many participants indicated their companies faced security issues, including security breaches. This could be because functionality and on-time shipping were prioritized and security was postponed. In fact, seven participants who reported vulnerabilities in shipped code indicated that when deadlines approach, they ship their code with a backdoor to address the security issues later. This behaviour is clearly troubling.
However, in general, our results are promising for software security. Whereas previous research  found that developers generally exhibit a “security is not my responsibility” attitude, the vast majority of our participants acknowledge the importance of software security and have specific procedures in place to address it. The few participants who indicated security is not important for their teams indicated that their software is not an interesting target to attackers. We do not imply that completely ignoring security is acceptable, but rather consider the possibility that these teams may be making an educated economic decision, having assessed the risk and found that it was negligible.
In addition, our participants appear to have a general understanding of what software security means, and they acknowledged that their applications may have security issues despite their efforts. It is interesting that some participants (n = 33) indicated that security is important for their teams and that they are satisfied with how they are handling software security, but also indicated that their software is likely vulnerable. We did not expect this combination. One explanation could be that participants were being pragmatic; there will always be security issues and you can never prove security . Another explanation could be that participants are satisfied that they are doing their best to ensure security given their circumstances, even if it may not be ideal or enough. Previous research  discussed that a lack of resources may discourage teams from addressing security or following security best practices. In our work, we found evidence that the lack of resources may be why participants believe that their applications are vulnerable, despite being satisfied with their practices. For example, 45% (15 of 33) of participants displaying this interesting combination indicated they lack at least one of: knowledge, awareness, budget, tools, time, and people-power to handle software security. In addition, the lack of security plans and resources were also reasons for deferring security at SMEs. These are reasonable reasons that may prevent teams or developers from focusing.
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
on software security. By identifying these deterrents, we can better focus our efforts on overcoming them, e.g., through providing better support for teams to devise security plans that fit their resources and work styles.
In general, our participants were self-motivated towards their work, as well as software security. Being a hard and cognitively demanding task , software security would likely benefit from developers’ self-motivation. Research showed that this type of motivation leads to better performance, engagement, and cognitive abilities . Thus, rather than relying mainly on external motivations (e.g., rewards), companies could focus their efforts on promoting internal motivations towards software security (e.g., by portraying security as their collective professional responsibility, and raising developers’ awareness of the implications of their code on their users and their company’s reputation). However, we should not expect developers to take on the challenge without adequate support. In addition to security tools and methodologies, developers should receive support within their workplace. For example, companies can work towards establishing security plans to guide developers’ security efforts. Companies and teams can also facilitate collaboration between developers and security experts. This collaboration can bridge the gap between the two groups , and would enable developers gain practical security experience which can improve their code.
# 8 LIMITATIONS
Conducting the survey online may have influenced data quality, but we took measures to filter out poor quality responses. The different methods of recruitment and compensation helped reach a broad range of participants, though, this difference may have influenced developers’ willingness to answer the survey. Our results are based on participants’ self-reported responses, which may be subject to bias and may not exactly represent real-life. However, we followed recommendations to reduce social-desirability bias by ensuring participants’ anonymity . The lists of software security strategies, motivations, and deterrents included in our survey are non-comprehensive. However, our lists reflect at least a subset of existing developers’ strategies, motivations and deterrents to software security .
# 9 CONCLUSION AND FUTURE WORK
We presented a survey study with 123 participants to explore how they address software security, as well as security motivators and deterrents. Participants consider security as part of their development process to varying degrees. Most interestingly, we believe that our results affirm that developers are not the weakest link. Our analysis shows that participants are self-driven in their work in general, as well as in their software security efforts. Our study are not explicitly ignoring security, dismissing it, or considering it outside of their responsibility. In fact, they are most motivated towards software security when they recognize and identify with its importance. On the other hand, the most important deterrents for software security relate to the (mis)management of the process. For example, dealing with competing priorities, and the lack of security plans, procedures, knowledge, or resources are the main causes for deferring security. Our work highlights the need to look beyond the individual and to focus on understanding organizational issues that lead to insecure practices.
For future work it would be interesting to explore potential relationships between motivations, deterrents, and strategies for software security (e.g., do certain deterrents lead developers to adopt certain strategies?) In addition, as our results indicated that experiencing a security issue (e.g., a breach) can increase software security awareness, it would be interesting to investigate security procedures and attitudes in companies that have experienced such issues and compare it to others that have not.
# 10 ACKNOWLEDGMENTS
We thank our participants for their time. H. Assal acknowledges her NSERC Postgraduate Scholarship (PGS-D). S. Chiasson acknowledges funding from NSERC for her Canada Research Chair and Discovery grants.
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK
# CHI 2019 Paper
# CHI 2019, May 4–9, 2019, Glasgow, Scotland, UK