# Obfuscation-Resilient Code Recognition in Android Apps
# Johannes Feichtner
# Graz University of Technology
# Secure Information Technology Center – Austria (A-SIT)
# ABSTRACT
Many Android developers take advantage of third-party libraries and code snippets from public sources to add functionality to apps. Besides making development more productive, external code can also be harmful, introduce vulnerabilities, or raise critical privacy issues that threaten the security of sensitive user data and amplify an app’s attack surface. Reliably recognizing such code fragments in Android applications is challenging due to the widespread use of obfuscation techniques and a variety of ways, how developers can express semantically similar program statements.
We propose a code recognition technique that is resilient against common code transformations and that excels in identifying code fragments and libraries in Android applications. Our method relies on obfuscation-resilient features from the Abstract Syntax Tree of methods and uses them in combination with invariant attributes from method signatures to derive well-characterizing fingerprints. To identify similar code, we elaborate an effective scoring metric that reliably compares fingerprints at method, class, and package level. We investigate how well our solution tackles obfuscated, shrunken, and optimized code by applying our technique to real-world applications. We thoroughly evaluate our solution and demonstrate its practical ability to fingerprint and recognize code with high precision and recall.
# CCS CONCEPTS
• Security and privacy → Mobile and wireless security.
# KEYWORDS
Android, Abstract Syntax Tree, Fingerprinting, Library Detection, Code Similarity, Code Recognition, Obfuscation
# ACM Reference Format:
Johannes Feichtner and Christof Rabensteiner. 2019. Obfuscation-Resilient Code Recognition in Android Apps. In Proceedings of the 14th International Conference on Availability, Reliability and Security (ARES 2019) (ARES ’19), August 26–29, 2019, Canterbury, United Kingdom. ACM, New York, NY, USA, 10 pages. https://doi.org/10/3339252
# 1 INTRODUCTION
Nowadays, most Android applications are bundled with third-party libraries that potentially include vulnerable or outdated code [ 13 ]. The Apache Cordova library, e.g., was affected by a vulnerability that enabled an attacker to interfere with an application’s behavior by sending malicious intents1. Providing the building blocks for a majority of cross-platform applications, this flaw immediately put the security of all of them at risk. Apart from introducing vulnerabilities, multiple studies  have demonstrated that code from external sources can also leak private information, exploit their privileges, or forward sensitive data to unauthorized parties.
Although Android libraries undoubtedly exhibit questionable security practices, insecure code snippets can also be located within app-specific code. If developers copy ready-to-use code snippets, e.g., from programming discussion platforms like Stack Overflow, they unknowingly might also introduce weaknesses. In 2017, a study  has revealed that 15% of 1 million inspected Android apps included security-related code snippets from Stack Overflow, whereas 97% of them contained security problems.
Since the use of third-party libraries and the integration of code snippets from external sources have evolved to common practices in app development, it is of utmost importance to find vulnerable code fragments. Despite significant research efforts to dissect apps and uncover such threats, reliable identification of insecure program parts remains challenging. Currently, code recognition in Android applications mostly targets third-party libraries and involves either whitelisting or a similarity-based strategy. In the former case, a precompiled whitelist of directories or package names is used as a reference to individual libraries. However, whitelists are usually gathered manually  and have to be maintained to stay up-to-date. Considering the constant intervention and the fact that it is practically infeasible to cover all libraries, this approach does not scale and is only suited for analysis scenarios without obfuscation.
The second approach consists in identifying libraries without prior knowledge [ 10 , 25 , 38 ]. Therefore, apps are decompiled and split into sets of potential library candidates. A similarity metric or hash-based comparison then measures the difference to candidates extracted from other apps. If the score exceeds a predefined threshold, candidates are considered to be the same libraries.
Although research has demonstrated the practical feasibility to identify code, existing work still leaves room for improvement:
1. Current approaches for code recognition in Android apps focus on detecting individual libraries by name and version. They require large amounts of ground truth for training and do not work effectively if the reference codebase is small or a priori incomplete. Pinpointing specific code snippets instead of full libraries is, thus, infeasible.
2. State-of-the-art methods strongly depend on Java package names, preserved directory hierarchies, and unaltered method signatures. However, package structures and names can be different in multiple versions of the same library. Also, during compilation, code can mutate as it undergoes automated.
1https://cordova.apache.org/announcements/2015/05/26/android-402.html
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Johannes Feichtner and Christof Rabensteiner
performance-related code optimizations, such as method inlining, duplicate code merging, and removal of unused method parameters. Focusing too much on such auxiliary information can, thus, give a false sense of a good classifier that is only reliable if trained libraries and tested apps exhibit the required attributes and do not apply optimizations.
(3) Android applications commonly apply code transformation techniques, including obfuscation, identifier renaming, and shrinking not only to optimize code but also to harden against various forms of abuse, such as tampering, reverse engineering, and intellectual property theft. While existing classification approaches might yield useful results despite such modifications, the recognition rate with real-world apps could significantly be improved if techniques were resilient to common types of obfuscation and code mangling.
In this paper, we address shortcomings of existing approaches and introduce a solution that is able to recognize arbitrary code fragments in Android apps, even if code transformation techniques, like shrinking or obfuscation, are applied. We overcome the aforementioned limitations by extracting and processing features from the Abstract Syntax Tree (AST) of methods. Our approach does not rely on identifiers of packages, classes, and methods and uses them only as supplementary information. Instead of a hash-based comparison, we measure the similarity of methods using vectorized fingerprints we derive from the AST of methods and transformation-invariant representations of method signatures. To compare code segments, we design a scoring metric that accurately determines inclusion within other code parts and can express the similarity of classes and packages based on an aggregation of fingerprints.
Compared to previous research, our solution excels in reliably recognizing code fragments, even if a very high degree of code obfuscation is applied and if the majority of originally trained code is no longer present, e.g., due to code merging or inlining. Our approach is scalable and succeeds in accurately matching individual small code snippets as well as entire libraries. Aimed at conditions that can be found with real-world apps, our solution is suited for arbitrary tasks that involve code recognition in Android apps.
# Contributions
Our key contributions are as follows:
- We present a framework to reliably recognize arbitrary code fragments in Android apps2. Our solution can overcome various limitations present in existing research and represents an effective method to identify used libraries, recognize specific code snippets, or find semantically similar candidates.
- We study features in code that are invariant to widely used code transformation techniques and propose a novel feature matching process that is resilient to code mangling, identifier renaming, shrinking, and optimizations, such as inlining, code merging, or removal of unused method parameters.
- We evaluate the quality of our algorithm by testing it with a set of open-source libraries. We compile all libraries multiple times with different forms of code transformations enabled and assess the impact on classification. Moreover, we ensure the soundness of our solution by thoroughly comparing the expressiveness of chosen features and threshold values for matching confidence and package particularity.
2The framework is available at: https://github.com/kstudent/astli
# Outline
In Section 2, we discuss related work. Section 3 introduces our approach for code recognition and highlights our selection of code features to overcome obfuscation. Subsequently, in Section 4 we present our algorithms for fingerprinting and matching. We evaluate our solution in Section 5 and conclude in Section 6.
# 2 RELATED WORK
Existing work addresses code recognition in Android apps mostly in the context of third-party library detection. In the following, we point out differences to our solution and also present related research on code clone detection and obfuscation analysis.
# Third-Party Library Detection
To investigate the security risks associated with using advertising libraries in mobile apps, early studies rely on a whitelist-based approach. Li et al. extend this concept to cover a general set of libraries. After manually collecting directory and package names of known libraries in a list, it is used to find matches in apps at a large scale. As such approaches fail if obfuscation techniques are used, more elaborate solutions based on machine learning and clustering have been proposed. PEDAL trains a classifier to detect libraries using features extracted from code. AdDetect, AnDarwin and WuKong build on the assumption that a library consists of only one package and segregate package hierarchies into distinct clusters. LibRadar augments the result by assigning each cluster a unique profile representing a library. However, the lack of ground truth and the use of heuristics comes at the cost of precision and does not consider partial library inclusions, e.g., as a consequence of code optimizations. Considering potentially obfuscated package names and deviating package hierarchies, LibD extracts features from code based on method invocations and inheritance relations within classes. Compared to them, our solution also relies on opcode sequences to find and match similar code fragments. However, in contrast to their approach, we can also match partial library occurrences as our fingerprints are composed independently of class inheritance or method overloading.
Tackling the prevalence of code obfuscation, LibScout comes closest to this work. Backes et al. leverage both method signatures and the package hierarchy structure to build profiles per library. An algorithm transforms method signatures into obfuscation-invariant fuzzy descriptors by removing identifiers and class types. These descriptors are then hashed and fed into a Merkle tree, representing the package hierarchy. Although their solution exhibits similar premises and requirements as ours, the differences are in how the overall problem has been approached. Besides obfuscation-invariant method signatures and symbolic package hierarchies, we also add features from the code implementation. While LibScout cannot handle libraries where more than 40% of the original code has been removed, fingerprints built on elements in the Abstract Syntax Tree enable us to recognize not only full libraries but also individual code snippets and library parts. At the same time, our approach helps to improve recognition rates if a shrinking code transformation has been applied. Consequently, our solution does not necessarily need large amounts of ground truth for matching and also works if at least a certain amount of code is available. Nonetheless, LibScout is expected to scale better as its approach to compare packages involves a smaller feature set than ours.
# Obfuscation-Resilient Code Recognition in Android Apps
ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Code Clone Detection
Malicious Android applications are often distributed by repackaging legitimate apps . The problem of uncovering small differences between two program versions is commonly referred to as clone or plagiarism detection and conceptually exhibits requirements similar to code recognition. Techniques for clone detection work on semantic and syntactic features of programs and measure the similarity of code based on tokens , parsing trees , or dependency graphs . Similar to our method, they coalesce code attributes to form a fingerprint that can then be pair-wise tested for equivalence with other candidates.
In a study, Potharaju et al.  investigate how attackers can leverage social engineering techniques and app repackaging to distribute malware in the Android market stores. They propose to compute fingerprints based on features extracted from the AST of methods. Therefore, the Android app archive is first transformed into a custom assembly language, followed by pruning the code of each method body, keeping only references to method calls and replacing all variable identifiers with the placeholder local for local variables or param otherwise. Of all method signatures, only the number of used arguments is preserved. The remaining instructions are then arranged as AST and used to derive a fingerprint vector. The algorithm leans on the hypothesis that two apps are similar if their fingerprints are located within a small neighborhood.
In our work, we adopt the concept as it yields a high detection rate with only 0% false positives and solves a problem that is close to ours. One advantage of working with feature vectors instead of full ASTs is the fact that comparing method becomes substantially cheaper than detecting graph isomorphism or computing the tree editing distance between ASTs . As their algorithm creates an app fingerprint as a sum of all method fingerprints, it requires that all code is present during matching. In our case, however, this requirement is not satisfiable as we assume that libraries and code parts may be incomplete or could have been removed during compilation. We, thus, design our own similarity metric that is resilient to common code transformations.
# App Code Obfuscation
In a survey from 2018, Wermke et al.  analyzed 1 million Android apps regarding the use of obfuscation techniques. According to the authors, 24% of apps are obfuscated, whereas the most prevalent obfuscation system is ProGuard. While the authors confirm that identifier renaming of classes, methods, and fields is among the most popular features, they make no statements about minified or shrunken apps. Nonetheless, in our solution, we address all variants of code obfuscation and optimizations that ProGuard offers to developers.
Most research of obfuscation in Android apps concentrated on reversing  and analyzing applications in spite of obfuscation . More recent studies specifically focus on obfuscated malware, such as a study by Hammad et al. , who assessed the impact of obfuscation on Android anti-malware products by inspecting 7 obfuscation strategies and 29 techniques. Also in this context, the work of Garcia et al.  inspects obfuscation-resilient properties to uncover malware using machine learning.
# 3 SYSTEM DESIGN
We design a static analysis framework to recognize code in Android app archives. The primary functionality can be split into two parts: In the learning phase, our tool is trained with code fragments or libraries. In the matching phase, we automatically analyze a given app and try to recognize code parts using previously learned data. The objectives of our solution can be summarized as follows:
1. If an app includes a library or code fragment, the tool should identify it both by name and version, if known.
2. The tool should work equally with obfuscated code.
3. After analyzing an app, the tool should list packages that resemble previously learned libraries or code fragments with a score indicating how much code has been matched.
# 3 Overcoming Obfuscation
In regular apps, code fragments and libraries can be recognized with reasonable certainty by matching the names of packages, classes, and methods. If code transformation techniques are applied, these identifiers become inconclusive. For a reliable identification nonetheless, we rely on features that (1) are suited to identify a code segment and remain the same for semantically similar sections of code, and (2) are invariant to common code transformations.
With these two properties in mind, our fingerprinting approach, as detailed in Section 4, is based on AST Vectors and Sanitized Signatures. AST vectors are vectors obtained by extracting structural dependencies of a method’s AST. Sanitized signatures result from removing all identifiers from a method signature. These identifiers include the method’s name and the class identifiers in all parameter types and the return type. We combine an AST vector and a sanitized signature to a fingerprint. Consequently, a grouped set of fingerprints can represent a package hierarchy. In the following, we explain how we overcome code transformation techniques.
# 3 Identifier Renaming
In this transformation, the obfuscator replaces debug symbols with meaningless character sequences. If activated during compilation, package names in the app archive will not disclose hints on included libraries. As our solution does not rely on identifiers at all, it is invariant to identifier renaming.
# 3 Shrinking
In this step, an obfuscator removes unused code from an app. In the learning phase, we cannot tell which parts of a library will be removed during app compilation. In preliminary tests, we identified cases where more than 90% of code was pruned. Shrinking does not only decide if an entire package gets in- or excluded; it can also remove unused methods and classes. As all methods in a class and classes in a package can be subject to dead code elimination, we consider this in the fingerprinting process.
# 3 Optimizations
Code optimizations involve adding, replacing, rearranging and removing code fragments. Although some of them can affect our features in theory, we can show in our evaluation all of these modifications have a minor impact on detection rates. Basically, a slight change in the AST vector does not necessarily inhibit a correct mapping, since the similarity between AST vectors is based on their distance. However, a sanitized signature that has been altered cannot lead back to the original method, since we check for strict equality when comparing signatures.
The obfuscator ProGuard offers 29 optimizations 3 to developers. Some of them have an impact on our features:
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Johannes Feichtner and Christof Rabensteiner
# Inlining
Hereby, ProGuard replaces a method invocation with the body of the invoked method. This usually affects short or unique methods but also tail recursive methods could be inlined. Inlining alters the AST vector. However, if only a short method is being inlined, we argue that the alteration is also limited.
# Code Merging
With this transformation, ProGuard identifies duplicated code fragments and merges them by modifying branch targets. Merging affects the AST vector as it reduces AST nodes.
# Method Parameter Removal
Hereby, ProGuard identifies unused parameters in methods and removes them from the signature. If applied, the sanitized signature will be altered and we will not be able to match it with the corresponding method.
# 4 WORKFLOW
The workflow of our approach starts by converting a given code fragment or library into the .dex format. This task is delegated to the build tool dx, which is provided by the Android SDK. Based on the Dalvik bytecode obtained, for each available method, we extract a fingerprint and arrange all of them within a package hierarchy (see Section 4). When learning code, we stop after this step and store the results in a database. When matching code, we compute a similarity score between 0 and 1, indicating whether given code fragments can be recognized fully, partially, or not at all by comparing with learned fingerprints and package hierarchies.
# 4 Fingerprinting Code
To derive fingerprints, we explain AST vectors in Section 4 and sanitized signatures in Section 4. The aggregation of fingerprints in package hierarchies is elaborated in Section 4. Finally, in Section 4, we give a practical example of a fingerprint derivation.
# Algorithm 1: Building a minimal AST from a method body
Input : Method Body
Output : Abstract Syntax Tree
1 AST ← createRootNode();
2 foreach instruction ∈ method body do
3      keep instructions with opcode in {INVOKE_DIRECT, INVOKE_VIRTUAL};
4      instructionNode ← createNode(instruction.opcode);
5      foreach parameter ∈ instruction do
6           parameterNode ← createNode(parameter.type);
7      end
8      instructionNode.addChild(parameterNode);
9 end
10 AST.addChild(instructionNode);
11 return AST
# 4 AST Vectors
We generate an AST vector by building an AST and conveying this tree to a vector. To compare methods, AST vectors are preferable over regular ASTs, as they allow to express the similarity of two methods by computing their distance. As depicted in Listing 1, we first build a minimal AST over a method body. Starting at the root node of a tree (line 1), we iterate over all program statements contained in the method (line 2) and filter instructions of the type INVOKE_DIRECT and INVOKE_VIRTUAL (line 3). We focus on these two as they are the most common method invocation calls according to Potharaju et. al. . However, for a more detailed vector, we could also keep track of further suffixes, i.e., _SUPER, _STATIC and _INTERFACE. Next, we create an AST node for the current invocation call (line 4) and attach a child node for each parameter of the method (lines 5-8). Finally, we add the instruction node as a child to the tree root (line 9).
# Algorithm 2: Conversion of an AST to an AST vector
Input : Abstract Syntax Tree
Output : Abstract Syntax Tree Vector
1 vector = createVector();
2 //count horizontal features; ∈ AST.getChildren() do
3 foreach invokeActionNode
4       #locals ← |{c ∈ invokeActionNode.getChildren() | c.type = local}|;
5       #params ← |{c ∈ invokeActionNode.getChildren() | c.type = param}|;
6       vector[local_local] ← #locals;
7       vector[param_param] ← 2#params;
8 end
9 foreach lvl1Node ∈ AST.getChildren() do
10       increment(vector[lvl1Node]);
11       foreach lvl2Node ∈ lvl1Node.getChildren() do
12            increment(vector[lvl2Node]);
13       end
14       increment(vector[lvl1Node, lvl2Node]);
15 end
16 return vector
We convert the AST into a vector by counting horizontal and vertical features, as defined by Potharaju et al. : A horizontal feature is a pair of leaf nodes with the same parent node, whereas a vertical feature is a directed path of arbitrary length, starting at the root node. Each dimension in our AST vector resembles the number of occurrences of a particular horizontal or vertical feature. As shown in Listing 2, starting with an empty vector (line 1), we count horizontal features by going through all first level nodes of the AST, determining the number of leaf pairs for each node (lines 3-8). For each invocation call, we count the number of local variables and parameters (lines 4-5), and compute the amount of pairs of type local-local and param-param (lines 6-7). Determining the number of pairs is equivalent to the handshake problem, so we can compute it using the binomial coefficient over 2. Next, we count the vertical features by iterating over first level nodes of the AST again (lines 10-16) and increment the occurrence count of the current node by 1 (line 11). Finally, we iterate over all of its children and increment occurrences of both paths, be it either 2nd-level relation only or a conjunction of first and second-level nodes (line 12).
# 4 Sanitized Signature
Sanitized signatures contain data from a method signature that is invariant to obfuscation. To sanitize the signature from features affected by obfuscation, we remove method identifiers, parameter names, and modifiers from the original signature. Further, we replace parameter types and the return type with a single letter code. For primitive types, we adopt the mapping from smali. Since object types can be subject to identifier renaming, they are mapped to an obfuscation-invariant token depending on its type.
# Obfuscation-Resilient Code Recognition in Android Apps
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
public ClassY doSomething(float[] number, ClassX x) {
return new ClassY(field1, number);
}
# Java Source Equivalent
.method public doSomething([FLhello/ClassX;)Lhello/ClassY;
new-instance v0, Lhello/ClassY;
iget v1, p0, Lhello/ClassX;->field1:I
invoke-direct {v0, v1, p1}, Lhello/ClassY;-><init>(I[F)V
return-object v0
.end method
# Fingerprint Extraction Example
# Recognizing Code Fingerprint
In the matching process, we are given a set of package hierarchies Pa, which we extracted from an Android app archive. For each package hierarchy pa ∈ Pa we pursue the following steps:
1. We sort all fingerprints in pa by particularity in descending order, such that we can choose a set of particular fingerprints. An explanation of particularity is given in Section 4.
2. For each fingerprint, we query the database for previously learned fingerprints with the same AST vector and sanitized signature. We collect the package hierarchies of similar fingerprints and store them in the candidate set Pl.
3. For each candidate pl ∈ Pl, we check if pa ⊆ pl, which means that the app package is included in the known package. Section 4 defines this relation and steps to compute it.
4. If pa ⊆ pl, we compute the similarity s(pa, pl), which depends on the AST vectors in pa and pl. Otherwise, we set s(pa, pl) to 0. Section 4 elaborates on the definition and computation of the similarity score.
5. We sort package candidates by similarity score in descending order and return the package with the highest score that meets a minimum threshold as a match.
# Fingerprint Particularity
Some fingerprints are more likely to match with unrelated fingerprints than others. When populating a set of candidates, rare fingerprints are preferable over frequent ones as they will less likely yield false positive candidates. In a test with 120,000 fingerprints, we observed that fingerprints with long AST vectors are more particular as they occur less frequently.
We approximate the particularity of a fingerprint with a score. Let m = (s, v) be a method fingerprint with a sanitized signature s and an AST vector v. The particularity score of m is defined as:
score(m) := ws · length(s) + wv · ∥v ∥1,                                              (1)
whereas length(s) returns the amount of character of s and ∥v ∥1 denotes the Manhattan distance of v. We weigh both dimensions with ws and wv in order to rectify the distributions.
# Inclusion
The inclusion relation ⊆ expresses if a package hierarchy p is included in a package hierarchy p′. Inclusion depends on the sanitized signatures in both package hierarchies. We use inclusion instead of equivalence in order to handle the loss of code when an obfuscator removes dead code from an app.
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Johannes Feichtner and Christof Rabensteiner
inclusion is reflexive and transitive, but not symmetric:
p ⊆ p′ ⇔ ∃fc : p 7→ p′, fc ... injective. (2)
In other words: Package p is included in package p′ if and only if there exists an injective mapping fc for all classes in p to the classes in p′. We require injectivity because we expect each code class to end up at most as one class in the app.
We add further requirements for our class mapping fc. Let c ∈ p be a class in the package p and c ′ ∈ p′. Then we have:
fc (c) = c ′ ⇒ c ⊆ c ′. (3)
If we map an app class c to a library class c′, then the app class is included in the library class. The inclusion relation between classes is defined analogously to the inclusion relation between packages:
c ⊆ c ′ ⇔ ∃fm : c 7→ c ′, fm ... injective. (4)
However, we can only map a fingerprint m ∈ c to a fingerprint m′ ∈ c ′ if their sanitized signatures are equal, or:
fm (m) = m′ ⇒ Signature of m and m′ are equal. (5)
Having defined inclusion for both packages and classes, we can now describe how our solution practically determines inclusion.
# Determining Class Inclusion
Let c = {s1, ..., sn} be a class consisting of sanitized signatures si (for the sake of simplicity, we ignore AST vectors and fingerprints for now). Then we can determine if c ⊆ c ′ in a greedy manner as described in Listing 3. The idea behind this approach is to find all signatures from c in c ′. If we find one, we delete it from the c ′ set such that we do not pick the given signature in c ′ twice. If we found all signatures from c in c ′, we know that there is an injective mapping fm and, thus, c ⊆ c.
# Determining Package Inclusion
In order to determine if package p is included in package p′, we need to find an injective mapping fc for all classes in p to classes in p′. This task is more challenging than the mapping fm for methods because of the lacking symmetry in the class inclusion relation. Figure 2 illustrates an example, where the greedy approach from Listing 3 fails.
We are given the packages p and p′, and we can tell that p ⊆ p′ because there exists an injective mapping fc with fc (c1) = c ′1 and fc (c2) = c 2′. However, the greedy approach fails because class c1′, since c1 ⊆ c ′2 holds. If we assign c1 to c 2′, we end up with c2 being unassigned, because of c2 ✚⊆ c 1′.
In the case where a valid assignment is not possible, we could backtrack by amending some assignments until we explore all possibilities. However, we opted to reduce the problem such that we can solve it with the Hungarian Algorithm . Given a set of workers, a set of tasks and a cost matrix, this algorithm assigns workers to tasks such that the overall costs are minimized. Instead of workers and tasks, we use classes of p and p′. We construct our cost matrix Ms as follows:
Ms ∈ {0, 1} |p|×|p′|, Ms [i, j] = (0 if ci ⊆ c ′j (6) 1 otherwise
If we apply the Hungarian Algorithm on Ms, we end up with an assignment fc. Since the algorithm minimizes the cost of fc, it prefers assignments that cost 0 over the ones that cost 1. Eventually, we compute the overall cost of fc with
cost(Ms, fc) := ÕMs [i, fc (i)]|p| (7)
i=1
and can argue that if
cost(Ms, fc) = 0 ⇔ ∃fc : p 7→ p′, fc ... injective. ⇔ p ⊆ p′ (8)
# Similarity Score
The similarity score helps us to determine how similar two packages hierarchies p and p′ are. The score depends on the similarity of AST vectors in the respective packages. Packages that are similar yield a higher score than packages that are not. Next, we explain how we measure the similarity between packages, classes, and AST vectors.
# Package Similarity
We compute the similarity score s(p, p′) by leveraging the Hungarian Algorithm, as it helps us to find the mapping between classes with maximum similarity. We fill the cost matrix S with the similarity score of the respective classes s(c, c ′):
S ∈ R|p|×|p′|, S[i, j] = (s(c, c ′) if ci ⊆ c ′j 0 otherwise (9)
Since the Hungarian Algorithm minimizes the costs in the cost matrix, we apply it on an inverted matrix Sinverted, where we negate each entry and shift it by the maximum:
Sinverted = (max(S) − S[i, j])i j (10)
After the Hungarian Algorithm generated a mapping fc, we can compute the similarity with cost(S, fc), as defined in Definition 7.
# Class Similarity
Let c = {m1, ..., mn} be a class consisting of a list of fingerprints mi where each fingerprint consists of a sanitized signature si and an AST vector vi. Then the class similarity s(c, c ′) can be determined with the Hungarian Algorithm once again.
First, we generate the cost matrix T:
T ∈ R|c|×|c′|, T [i, j] = (s(vi, v j ′) if si = s j′ (11) 0 otherwise
We invert T as in Equation 10 and let the Hungarian Algorithm find the best assignment. We use the cost function cost(T, fc) in Definition 7 to determine the similarity score s(c, c ′).
# Obfuscation-Resilient Code Recognition in Android Apps
# 4 AST Vector Similarity
We express the similarity between two AST vectors v and v ′ with the following formula:
s(v, v ′) = max(0, ∥v ∥1 − ∥v − v ′∥1) (12)
We use the Manhattan distance to determine distance and length of vectors, as proposed in . Our formula fulfills these requirements:
- We want the similarity to be 0 if the vectors are too far apart. The threshold where similarity becomes 0 is reached if the difference between two vectors is greater than the vector itself.
- We do not accept negative values for similarity, as we want to avoid the situation where a mismatch of vectors worsens the overall score of an assignment. We ensure this requirement by taking the maximum between the difference and 0.
- We require maximum similarity when both vectors are equal. In that case ∥v − v ′∥1 becomes 0, such that s(v, v ′) = ∥v ∥1.
- If ∥v1 ∥1 > ∥v2 ∥1, we require s(v1, v1) > s(v2, v2) because we want larger and therefore more particular vectors to have more influence on the assignment cost.
# 5 EVALUATION
The goal of this evaluation is twofold. First, we investigate how well AST vectors and sanitized signatures fingerprint code and tackle obfuscation (see Section 5). Second, applying our solution on a set of open-source Android apps, we assess (1) how much code of a library is needed to accurately recognize it (see Section 5), (2) how much confidence a match should have to be significant (see Section 5), and (3) how well we can recognize individual libraries when different obfuscation techniques are applied (see Section 5).
# 5 Method and Dataset
In the learning phase, we seek to assign similar fingerprints to semantically similar code fragments. Distinctive features should characterize unrelated code. To better understand how well AST vectors and sanitized signatures identify code, as a first step, we test our features using a home-made app that is obfuscated, includes two libraries, and 150 packages. The results give an intuition on how changes in the codebase or parameters affect the tool’s accuracy.
To evaluate how our solution can recognize code in real-world apps, we chose to crawl the F-Droid Repository7. Since this app repository offers only Free and Open Source Software (FOSS), we can download the source codes of apps including configuration files for the Gradle build system. From these files, which are needed for compilation only but are not included in final Android app archives, we can extract a list of used library packages. On their basis, we split the code into different parts to derive fingerprints for each of them. Moreover, we adapted the build files of all downloaded FOSS apps to compile multiple versions with different code transformation techniques enabled: shrunken, obfuscated, shrunken + obfuscated, shrunken + obfuscated + optimized. For this evaluation, we crawled source codes of 800 FOSS apps and compiled one regular and four transformed versions, resulting in 4,000 app samples overall.
The collected dataset enables us to unambiguously verify how well learned code can be recognized. Based on the assumption that FOSS apps exhibit the same library inclusion as other apps, our results should also hold for arbitrary Android applications.
# 5 Fingerprint Quality
Our algorithm derives a representation of code using AST vectors and sanitized signatures. We designed these techniques to be invariant to commonly used code transformations while still being able to characterize individual code parts precisely.
# 5 Setup
To build a confusion matrix, we use the sample set of 150 packages included in our obfuscated test app. The set is large enough to feature a variety of different packages and sufficient to visualize confusion. We compute the similarity score between each app package with each library package we learned before.
# 5 Results
As depicted in Figure 3, we derived three matrices that show confusion when only AST vectors or sanitized signatures are used for code identification, and with both features combined. The x and y-axes are sorted by package particularity (see Section 4). Packages with small particularity are located on the top/left, whereas packages on bottom/right have high particularity.
With AST vectors, code similarity is confident on the main diagonal but overall prone to confusion. The upper right part of the matrix shows many packages that have been mislabeled with high confidence. We can explain this observation by the fact that a small app package can be easily mapped to a large library package. The other way around does not hold: large app packages are not confused with small library packages.
The confusion matrix for sanitized signatures shows that the similarity measure is either absolutely confident that a package is included (see Section 4) in another one, or otherwise not confident at all. Compared to AST vector similarity, we observe less confusion in the upper right part of the matrix, where less particular app packages are compared to more particular library packages. Confusion, however, occurs with small app packages as large packages are likely to contain all signatures of small packages.
With both features combined, confusion is mostly eliminated aside from low particularity packages in the top rows of the matrix. The small clusters around the main diagonal in the top left area result from packages that implement the same interfaces and are, thus, semantically related. Overall, we see that the combination of AST vectors and sanitized signatures can identify code almost without confusion and, thereby, paves the way for accurate recognition.
# 5 Threshold for Package Particularity
The confusion matrix for AST vectors and sanitized signatures combined showed that the remaining confusion was caused by packages with low particularity. As a remedy for confusion and to improve accuracy, we introduce the threshold for minimum package particularity (tpp). It decides whether a particular package is sufficiently expressive to be used for learning and matching.
7 https://f-droid.org
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Johannes Feichtner and Christof Rabensteiner
# AST Vectors
# Sanitized Signatures
# Combined
Before processing an app package, we check if the package is particular enough. If not, we simply ignore it as we cannot rely on its matches. The higher we choose tpp, the more accurate recognition becomes. However, with a high tpp we ignore more packages and, thus, identify fewer code fragments overall. In the following, we measure this influence with the keep ratio:
keep ratio = |Analyzed Packages of App| (13)
Our goal is to find a reasonable value for tpp that represents a compromise between recognition accuracy and keep ratio.
Question: How much particularity is needed for precise recognition?
# 5 Setup.
We use our set of real-world apps and iteratively try recognition with values between 0 and 200 for tpp. After each round, we build a confusion matrix and compute accuracy and keep ratio.
# 5 Results.
As also observed in Figure 3, confusion arises below a certain package particularity but decreases above a specific particularity. Hence, we see that a tpp value of 80 delivers the highest accuracy without dropping too many packages. If a high keep ratio is targeted instead of accuracy, any value for tpp below 80 would be reasonable.
# 5 Threshold for Matching Confidence
As explained in Section 4, we express the similarity between an app package pa and a library package pl with the similarity score s(pa, pl). This score depends both on how similar and on how particular packages are: More particular packages result in a higher score, whereas less particular packages are scored lower. This imbalance is problematic when deciding on whether a recognition result is significant. A constant threshold for all packages favors more particular packages over less particular ones with no regard to the actual similarity. To counteract, we derive the confidence we put into a match from the package similarity as follows:
confidence(pa, pl) = s(pa, pa)s(pa, pl) (14)
The resulting value is ∈  because 0 ≤ s(pa, pl) < s(pa, pa).
Our goal is to find a reasonable threshold (tmc) that indicates if a recognition result is significant enough to be accepted.
# 5 Setup.
To find the best value for tmc, we use our sample set of FOSS apps and remodel the multi-class problem into a binary classification problem with the One-Vs-All approach. The binary classifier tells whether a package is known (positive, +) or unknown to the system (negative, -). We transform each match into the new problem domain by expressing learned library packages as positive, and all others, e.g., unlearned packages or app packages, as negative.
With our recognition results transformed into binary classifications, we build Receiver Operational characteristics (ROC) curves that can illustrate the performance of a binary classifier and reveal how the accept threshold for confidence influences both true and false positive rate. The ROC curves shed light on the separability of known and unknown packages and help in finding a reasonable threshold value for matching confidence tmc. We repeat this process for all app samples to determine how well we can distinguish known from unknown packages if code transformations are used.
# 5 Results.
# Obfuscation-Resilient Code Recognition in Android Apps
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# True Positive Rate
with obfuscation, shrinking and optimizations activated. In this build type the AUC is 87%, which is still acceptable.
# 5 Code Recognition
In Section 4, we elaborated a workflow to recognize learned code by computing fingerprints of methods, aggregating them in package hierarchies and testing for similarity with known packages. Question: How well does our approach recognize app packages?
# 5 Setup.
For this scenario, use our FOSS sample set and analyze all apps in all build types. Aimed at highest recognition accuracy, we set the thresholds for matching confidence tmc to 0 (see Section 5) and for package particularity tpp to 80 (see Section 5). To all obtained results, we apply the following multiclass performance metrics  by using the formulas shown in Figure 7:
- Accuracy: Determines how many app packages have been labeled correctly in relation to all recognition matches.
- Precision: Ability of our solution to not mislabel packages.
- Recall: Ability to find all instances of a package.
- F1 Score: Harmonic mean between Precision and Recall.
n . . . amount of matches, l . . . amount of known packages, pi . . . app package.
# 5 Results.
The recognition results are summarized in Table 1. As shown, all metrics perform well in all build types except for the set of obfuscated, shrunken, and optimized apps. By manually investigating classifications, we noticed that the optimization technique Method Parameter Removal causes the weaker performance with this build type (see Section 3). With this code transformation enabled, ProGuard prunes method signatures from unused parameters, leading to different sanitized signatures. Nonetheless, the use of AST vectors ensures that recognition is still feasible.
# 5 Summary
We examined how AST vectors and sanitized signatures align with real-world apps that use code transformations. First, we assessed how well our techniques describe obfuscated code fragments. Three confusion matrices revealed that although each technique is capable of identifying obfuscated code on its own, results are significantly improved when both features are combined. We also noticed that most confusion arises in packages with low particularity. Therefore, we introduced a threshold tpp value that indicated how much code was relevant to keep high accuracy high while not dropping too much packages. We also introduced a match confidence threshold tmc to decide on whether to accept or to reject a recognition result. To find a reasonable value for tmc we remodeled our problem into binary classification. ROC curves underlined how well we can distinguish known from unknown packages despite code transformation. In our final study, we tested code recognition with a set of Android app samples and found that our solution delivers high values for accuracy, precision, recall, and F-Score in all scenarios.
# ARES ’19, August 26–29, 2019, Canterbury, United Kingdom
# Johannes Feichtner and Christof Rabensteiner
# 6 CONCLUSION
The use of third-party libraries and the integration of code snippets from public sources have become common practices in Android application development. Security issues and vulnerabilities in such components reach a high number of end-users and put sensitive data at risk. However, a precise recognition of such program parts is challenging if code transformation techniques were applied.
In this work, we presented a solution that can reliably recognize code snippets or libraries even if obfuscation, shrinking, or similar techniques are used. By extracting fingerprints from the Abstract Syntax Tree of methods and combining them with obfuscation-resilient features of method signatures, we succeed in accurately characterizing code. We thoroughly evaluated the applicability of our technique and demonstrated that can we describe and recognize code fragments with high precision. Our solution contributes to an effective identification of problematic code in Android applications.